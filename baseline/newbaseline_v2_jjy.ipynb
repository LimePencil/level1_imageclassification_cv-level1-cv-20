{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam, RMSprop, AdamW\n",
    "from adamp import AdamP\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, ExponentialLR\n",
    "from torch.utils.data import Dataset, Subset, random_split, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config():\n",
    "    seed = 42\n",
    "    \n",
    "    # 데이터\n",
    "#     data_dir = './face_input/train' #\n",
    "    data_dir = './input/data/train'\n",
    "#     resize = [256, 256]\n",
    "    resize = [224, 224]\n",
    "    val_ratio = 0.1\n",
    "    \n",
    "    # 학습 설정\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "#     batch_size = 16\n",
    "    valid_batch_size = 1000\n",
    "    lr = 0.0001\n",
    "    lr_decay_step = 5\n",
    "    log_interval = 50\n",
    "    \n",
    "    # 세이브 경로\n",
    "    save_dir = './newAgeModel_exp'\n",
    "    multi_dir = './newModel_exp2'\n",
    "    \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 함수\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base setting\n",
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "    \n",
    "    @classmethod\n",
    "    def class2number(cls, value: int) -> int:\n",
    "        if value <= 2:\n",
    "            return cls.YOUNG\n",
    "        elif value <= 8:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD\n",
    "        \n",
    "    @classmethod\n",
    "    def from_cls(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 20:\n",
    "            return 0\n",
    "        elif value < 25:\n",
    "            return 1\n",
    "        elif value < 30:\n",
    "            return 2\n",
    "        elif value < 35:\n",
    "            return 3\n",
    "        elif value < 40:\n",
    "            return 4\n",
    "        elif value < 45:\n",
    "            return 5\n",
    "        elif value < 50:\n",
    "            return 6\n",
    "        elif value < 55:\n",
    "            return 7\n",
    "        elif value < 60:\n",
    "            return 8\n",
    "        else:\n",
    "            return 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define transform (Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=(0.548, 0.504, 0.479)\n",
    "std=(0.237, 0.247, 0.246)\n",
    "train_transform = Compose([\n",
    "    RandomCrop(height=460, width=320),\n",
    "    HorizontalFlip(p=0.5),\n",
    "#     ShiftScaleRotate(p=0.5),\n",
    "#     HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    CLAHE(p=0.1),\n",
    "#     RandomScale(scale_limit=0.1, interpolation=cv2.INTER_LINEAR, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#     GaussNoise(p=0.5),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0, interpolation=cv2.INTER_LINEAR),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)\n",
    "val_transform = Compose([\n",
    "    CenterCrop(height=460, width=320),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newBaseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, indices, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "        self._file_names = {\n",
    "            \"mask1\": MaskLabels.MASK,\n",
    "            \"mask2\": MaskLabels.MASK,\n",
    "            \"mask3\": MaskLabels.MASK,\n",
    "            \"mask4\": MaskLabels.MASK,\n",
    "            \"mask5\": MaskLabels.MASK,\n",
    "            \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "            \"normal\": MaskLabels.NORMAL\n",
    "        }\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        csv_path = os.path.join(self.img_dir, 'train.csv')\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        csv_data = csv_data.loc[self.indices]\n",
    "        csv_data_list = list(csv_data.values)\n",
    "        cnt = 0\n",
    "        for id, gender, _, age, path in csv_data_list:\n",
    "            img_folder = os.path.join(self.img_dir, 'images', path)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "                    \n",
    "                img_path = os.path.join(img_folder, file_name)  # (data_path, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_cls(age)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + AgeLabels.class2number(age_label)\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, (mask_label, gender_label, age_label, multi_class_label) # multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Sampler(ImbalancedDatasetSampler):\n",
    "#     def _get_labels(self, dataset):\n",
    "#         return [dataset.dataset.class_list[i] for i in dataset.indices]\n",
    "\n",
    "class Sampler(ImbalancedDatasetSampler):\n",
    "    def _get_labels(self, dataset):\n",
    "        return dataset.age_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(config.data_dir,'train.csv')\n",
    "data = pd.read_csv(csv_path)\n",
    "age_0 = data['age'][lambda x : (x < 20)].count()\n",
    "age_1 = data['age'][lambda x : (x >= 20) & (x<25)].count()\n",
    "age_2 = data['age'][lambda x : (x >= 25) & (x<30)].count()\n",
    "age_3 = data['age'][lambda x : (x >= 30) & (x<35)].count()\n",
    "age_4 = data['age'][lambda x : (x >= 35) & (x<40)].count()\n",
    "age_5 = data['age'][lambda x : (x >= 40) & (x<45)].count()\n",
    "age_6 = data['age'][lambda x : (x >= 45) & (x<50)].count()\n",
    "age_7 = data['age'][lambda x : (x >= 50) & (x<55)].count()\n",
    "age_8 = data['age'][lambda x : (x >= 55) & (x<60)].count()\n",
    "age_9 = data['age'][lambda x : x >= 60].count()\n",
    "age_img_num_per_cls =  torch.Tensor([age_0, age_1, age_2, age_3, age_4, age_5, age_6, age_7, age_8, age_9])\n",
    "\n",
    "length = len(data)\n",
    "n_val = int(length * config.val_ratio)\n",
    "val_indices = set(random.choices(range(length), k=n_val))\n",
    "train_indices = set(range(length)) - val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = newBaseDataset(img_dir = config.data_dir, indices = train_indices)\n",
    "val_dataset = newBaseDataset(img_dir = config.data_dir, indices = val_indices)\n",
    "train_dataset.set_transform(train_transform)\n",
    "val_dataset.set_transform(val_transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    sampler=Sampler(train_dataset),\n",
    "#     shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=use_cuda\n",
    "    \n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.valid_batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SwinMultiheadModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.swin_b(weights='DEFAULT')\n",
    "#         self.base_model.head = Identity()\n",
    "\n",
    "#         self.fc_mask_head = nn.Sequential(\n",
    "#             nn.Linear(in_features=1024, out_features=1000, bias=True),\n",
    "#             nn.BatchNorm1d(1000),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(0.5, inplace=True),\n",
    "#             nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "#         )\n",
    "#         self.fc_gender_head = nn.Sequential(\n",
    "#             nn.Linear(in_features=1024, out_features=1000, bias=True),\n",
    "#             nn.BatchNorm1d(1000),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(0.5, inplace=True),\n",
    "#             nn.Linear(in_features=1000, out_features=2, bias=True)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.base_model(x)\n",
    "#         mask = self.fc_mask_head(x)\n",
    "#         gender = self.fc_gender_head(x)\n",
    "#         return mask, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SwinAgeModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.swin_b(weights='DEFAULT')\n",
    "#         self.base_model.head = nn.Sequential(\n",
    "#             nn.Linear(in_features=1024, out_features=1000, bias=True),\n",
    "#             nn.BatchNorm1d(1000),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(0.5, inplace=True),\n",
    "#             nn.Linear(in_features=1000, out_features=1000, bias=True),\n",
    "#             nn.BatchNorm1d(1000),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(0.5, inplace=True),\n",
    "#             nn.Linear(in_features=1000, out_features=10, bias=True)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = self.base_model(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResMultiheadModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.DEFAULT)\n",
    "        self.base_model.fc = Identity()\n",
    "\n",
    "        self.fc_mask = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "        )\n",
    "        self.fc_gender = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=2, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        mask = self.fc_mask(x)\n",
    "        gender = self.fc_gender(x)\n",
    "        return mask, gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResAgeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.DEFAULT)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=1000, bias=True),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=10, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi = ResMultiheadModel()\n",
    "model_age = ResAgeModel()\n",
    "\n",
    "model_multi_path = os.path.join(config.multi_dir, f'best_total_multi.pth') #best_age.pth\n",
    "model_multi.load_state_dict(torch.load(model_multi_path, map_location=device))\n",
    "\n",
    "model_multi = model_multi.to(device)\n",
    "model_age = model_age.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train (Age only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()\n",
    "    \n",
    "class LADELoss(nn.Module):\n",
    "    def __init__(self, num_classes=10, img_num_per_cls=None, remine_lambda=0.1):\n",
    "        super().__init__()\n",
    "        if img_num_per_cls is not None:\n",
    "#             self.img_num_per_cls = calculate_prior(num_classes, img_max, prior, prior_txt, return_num=True).float().cuda()\n",
    "            self.img_num_per_cls = img_num_per_cls\n",
    "            self.prior = self.img_num_per_cls / self.img_num_per_cls.sum()\n",
    "        else:\n",
    "            self.prior = None\n",
    "        self.prior = self.prior.to(device)\n",
    "        self.balanced_prior = torch.tensor(1. / num_classes).float().cuda()\n",
    "        self.remine_lambda = remine_lambda\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.cls_weight = (self.img_num_per_cls.float() / torch.sum(self.img_num_per_cls.float())).cuda()\n",
    "\n",
    "    def mine_lower_bound(self, x_p, x_q, num_samples_per_cls):\n",
    "        N = x_p.size(-1)\n",
    "        first_term = torch.sum(x_p, -1) / (num_samples_per_cls + 1e-8)\n",
    "        second_term = torch.logsumexp(x_q, -1) - np.log(N)\n",
    "\n",
    "        return first_term - second_term, first_term, second_term\n",
    "\n",
    "    def remine_lower_bound(self, x_p, x_q, num_samples_per_cls):\n",
    "        loss, first_term, second_term = self.mine_lower_bound(x_p, x_q, num_samples_per_cls)\n",
    "        reg = (second_term ** 2) * self.remine_lambda\n",
    "        return loss - reg, first_term, second_term\n",
    "\n",
    "    def forward(self, y_pred, target, q_pred=None):\n",
    "        \"\"\"\n",
    "        y_pred: N x C\n",
    "        target: N\n",
    "        \"\"\"\n",
    "        per_cls_pred_spread = y_pred.T * (target == torch.arange(0, self.num_classes).view(-1, 1).type_as(target))  # C x N\n",
    "        pred_spread = (y_pred - torch.log(self.prior + 1e-9) + torch.log(self.balanced_prior + 1e-9)).T  # C x N\n",
    "\n",
    "        num_samples_per_cls = torch.sum(target == torch.arange(0, self.num_classes).view(-1, 1).type_as(target), -1).float()  # C\n",
    "        estim_loss, first_term, second_term = self.remine_lower_bound(per_cls_pred_spread, pred_spread, num_samples_per_cls)\n",
    "\n",
    "        loss = -torch.sum(estim_loss * self.cls_weight)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss , metric , optimizer , scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = FocalLoss()\n",
    "\n",
    "# criterion_mask = FocalLoss() # F1Loss(classes=3)\n",
    "# criterion_age = LADELoss(num_classes=10, img_num_per_cls=age_img_num_per_cls) #F1Loss(classes=3)\n",
    "# criterion_gender = FocalLoss() #F1Loss(classes=2)\n",
    "\n",
    "# criterion_age = F1Loss(classes=10)\n",
    "criterion_age = FocalLoss()\n",
    "# optimizer_multi = AdamP(\n",
    "#     filter(lambda p: p.requires_grad, model_multi.parameters()),\n",
    "#     lr=config.lr,\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "optimizer_age = Adam(\n",
    "    filter(lambda p: p.requires_grad, model_age.parameters()),\n",
    "    lr=config.lr,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "scheduler_age = StepLR(optimizer_age, config.lr_decay_step, gamma=0.5)\n",
    "# scheduler_multi = CosineAnnealingLR(optimizer_multi, T_max=2, eta_min=0.)\n",
    "# scheduler_age = CosineAnnealingLR(optimizer_age, T_max=2, eta_min=0.)\n",
    "# -- scheduler: ReduceLROnPlateau\n",
    "# 성능이 향상되지 않을 때 learning rate를 줄입니다. patience=10은 10회 동안 성능 향상이 없을 경우입니다.\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "# -- scheduler: CosineAnnealingLR\n",
    "# CosineAnnealing은 learning rate를 cosine 그래프처럼 변화시킵니다.\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path : newAgeModel_exp2\n"
     ]
    }
   ],
   "source": [
    "# 세이브 경로\n",
    "path = Path(config.save_dir)\n",
    "if (not path.exists()):\n",
    "    save_dir = str(path)\n",
    "else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    save_dir = f\"{path}{n}\"\n",
    "\n",
    "print(\"save path : \" + save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(log_dir=save_dir)\n",
    "with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(vars(config), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50](50/267)\n",
      "     [ Age ] training loss 0.1808 || age f1 0.839 || lr 0.0001\n",
      "     [Total] Acc 96.62% || f1-score 0.9446\n",
      "Epoch[0/50](100/267)\n",
      "     [ Age ] training loss 0.1423 || age f1 0.8588 || lr 0.0001\n",
      "     [Total] Acc 97.94% || f1-score 0.9633\n",
      "Epoch[0/50](150/267)\n",
      "     [ Age ] training loss 0.1115 || age f1 0.8866 || lr 0.0001\n",
      "     [Total] Acc 98.09% || f1-score 0.9664\n",
      "Epoch[0/50](200/267)\n",
      "     [ Age ] training loss 0.09219 || age f1 0.909 || lr 0.0001\n",
      "     [Total] Acc 98.34% || f1-score 0.9771\n",
      "Epoch[0/50](250/267)\n",
      "     [ Age ] training loss 0.08731 || age f1 0.9149 || lr 0.0001\n",
      "     [Total] Acc 98.56% || f1-score 0.9793\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for Age || f1 : 0.4067! saving the best multi model..\n",
      "New best model for Total || f1 : 0.7796! saving the best multi model..\n",
      "[ Val_Age ] loss 0.8614 || age f1 0.4067\n",
      "[Val_Total] Acc 87.54% || f1-score 0.7796\n",
      "[  Best   ] age_f1 0.4067 || total_f1 0.7796\n",
      "\n",
      "Epoch[1/50](50/267)\n",
      "     [ Age ] training loss 0.06536 || age f1 0.9342 || lr 0.0001\n",
      "     [Total] Acc 98.94% || f1-score 0.9823\n",
      "Epoch[1/50](100/267)\n",
      "     [ Age ] training loss 0.05684 || age f1 0.9375 || lr 0.0001\n",
      "     [Total] Acc 98.78% || f1-score 0.9807\n",
      "Epoch[1/50](150/267)\n",
      "     [ Age ] training loss 0.05696 || age f1 0.9403 || lr 0.0001\n",
      "     [Total] Acc 99.06% || f1-score 0.9848\n",
      "Epoch[1/50](200/267)\n",
      "     [ Age ] training loss 0.05702 || age f1 0.9446 || lr 0.0001\n",
      "     [Total] Acc 98.91% || f1-score 0.9858\n",
      "Epoch[1/50](250/267)\n",
      "     [ Age ] training loss 0.05862 || age f1 0.9485 || lr 0.0001\n",
      "     [Total] Acc 98.97% || f1-score 0.983\n",
      "\n",
      "Calculating validation results...\n",
      "[ Val_Age ] loss 0.895 || age f1 0.4054\n",
      "[Val_Total] Acc 86.91% || f1-score 0.7522\n",
      "[  Best   ] age_f1 0.4067 || total_f1 0.7796\n",
      "\n",
      "Epoch[2/50](50/267)\n",
      "     [ Age ] training loss 0.0395 || age f1 0.9547 || lr 0.0001\n",
      "     [Total] Acc 98.97% || f1-score 0.9798\n",
      "Epoch[2/50](100/267)\n",
      "     [ Age ] training loss 0.05107 || age f1 0.952 || lr 0.0001\n",
      "     [Total] Acc 99.19% || f1-score 0.9862\n",
      "Epoch[2/50](150/267)\n",
      "     [ Age ] training loss 0.03931 || age f1 0.957 || lr 0.0001\n",
      "     [Total] Acc 99.06% || f1-score 0.9914\n",
      "Epoch[2/50](200/267)\n",
      "     [ Age ] training loss 0.03964 || age f1 0.9614 || lr 0.0001\n",
      "     [Total] Acc 99.31% || f1-score 0.991\n",
      "Epoch[2/50](250/267)\n",
      "     [ Age ] training loss 0.03961 || age f1 0.9628 || lr 0.0001\n",
      "     [Total] Acc 99.41% || f1-score 0.9916\n",
      "\n",
      "Calculating validation results...\n",
      "[ Val_Age ] loss  1.1 || age f1 0.3586\n",
      "[Val_Total] Acc 86.28% || f1-score 0.7752\n",
      "[  Best   ] age_f1 0.4067 || total_f1 0.7796\n",
      "\n",
      "Epoch[3/50](50/267)\n",
      "     [ Age ] training loss 0.02658 || age f1 0.9729 || lr 0.0001\n",
      "     [Total] Acc 99.34% || f1-score 0.9917\n",
      "Epoch[3/50](100/267)\n",
      "     [ Age ] training loss 0.02499 || age f1 0.9748 || lr 0.0001\n",
      "     [Total] Acc 99.50% || f1-score 0.9937\n",
      "Epoch[3/50](150/267)\n",
      "     [ Age ] training loss 0.02276 || age f1 0.9776 || lr 0.0001\n",
      "     [Total] Acc 99.50% || f1-score 0.9926\n",
      "Epoch[3/50](200/267)\n",
      "     [ Age ] training loss 0.02873 || age f1 0.9752 || lr 0.0001\n",
      "     [Total] Acc 99.44% || f1-score 0.9935\n",
      "Epoch[3/50](250/267)\n",
      "     [ Age ] training loss 0.0309 || age f1 0.9691 || lr 0.0001\n",
      "     [Total] Acc 99.25% || f1-score 0.9888\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for Age || f1 : 0.4104! saving the best multi model..\n",
      "[ Val_Age ] loss 1.031 || age f1 0.4104\n",
      "[Val_Total] Acc 87.76% || f1-score 0.7656\n",
      "[  Best   ] age_f1 0.4104 || total_f1 0.7796\n",
      "\n",
      "Epoch[4/50](50/267)\n",
      "     [ Age ] training loss 0.0226 || age f1 0.9786 || lr 0.0001\n",
      "     [Total] Acc 99.28% || f1-score 0.9899\n",
      "Epoch[4/50](100/267)\n",
      "     [ Age ] training loss 0.03023 || age f1 0.9727 || lr 0.0001\n",
      "     [Total] Acc 99.03% || f1-score 0.9842\n",
      "Epoch[4/50](150/267)\n",
      "     [ Age ] training loss 0.03401 || age f1 0.9696 || lr 0.0001\n",
      "     [Total] Acc 99.00% || f1-score 0.9847\n",
      "Epoch[4/50](200/267)\n",
      "     [ Age ] training loss 0.04045 || age f1 0.9593 || lr 0.0001\n",
      "     [Total] Acc 99.03% || f1-score 0.988\n",
      "Epoch[4/50](250/267)\n",
      "     [ Age ] training loss 0.03696 || age f1 0.9651 || lr 0.0001\n",
      "     [Total] Acc 99.47% || f1-score 0.993\n",
      "\n",
      "Calculating validation results...\n",
      "[ Val_Age ] loss 1.049 || age f1 0.3814\n",
      "[Val_Total] Acc 87.19% || f1-score 0.7587\n",
      "[  Best   ] age_f1 0.4104 || total_f1 0.7796\n",
      "\n",
      "Epoch[5/50](50/267)\n",
      "     [ Age ] training loss 0.02383 || age f1 0.9785 || lr 5e-05\n",
      "     [Total] Acc 99.41% || f1-score 0.9928\n",
      "Epoch[5/50](100/267)\n",
      "     [ Age ] training loss 0.01241 || age f1 0.9863 || lr 5e-05\n",
      "     [Total] Acc 99.66% || f1-score 0.9971\n",
      "Epoch[5/50](150/267)\n",
      "     [ Age ] training loss 0.01203 || age f1 0.9893 || lr 5e-05\n",
      "     [Total] Acc 99.47% || f1-score 0.9949\n",
      "Epoch[5/50](200/267)\n",
      "     [ Age ] training loss 0.005907 || age f1 0.9941 || lr 5e-05\n",
      "     [Total] Acc 99.66% || f1-score 0.9966\n",
      "Epoch[5/50](250/267)\n",
      "     [ Age ] training loss 0.007856 || age f1 0.9913 || lr 5e-05\n",
      "     [Total] Acc 99.66% || f1-score 0.9967\n",
      "\n",
      "Calculating validation results...\n",
      "[ Val_Age ] loss 1.057 || age f1 0.3917\n",
      "[Val_Total] Acc 87.42% || f1-score 0.7726\n",
      "[  Best   ] age_f1 0.4104 || total_f1 0.7796\n",
      "\n",
      "Epoch[6/50](50/267)\n",
      "     [ Age ] training loss 0.008823 || age f1 0.993 || lr 5e-05\n",
      "     [Total] Acc 99.59% || f1-score 0.9962\n",
      "Epoch[6/50](100/267)\n",
      "     [ Age ] training loss 0.008622 || age f1 0.9928 || lr 5e-05\n",
      "     [Total] Acc 99.62% || f1-score 0.9974\n",
      "Epoch[6/50](150/267)\n",
      "     [ Age ] training loss 0.00859 || age f1 0.9917 || lr 5e-05\n",
      "     [Total] Acc 99.69% || f1-score 0.995\n",
      "Epoch[6/50](200/267)\n",
      "     [ Age ] training loss 0.006613 || age f1 0.9928 || lr 5e-05\n",
      "     [Total] Acc 99.75% || f1-score 0.9965\n",
      "Epoch[6/50](250/267)\n",
      "     [ Age ] training loss 0.005478 || age f1 0.9955 || lr 5e-05\n",
      "     [Total] Acc 99.66% || f1-score 0.9935\n",
      "\n",
      "Calculating validation results...\n",
      "[ Val_Age ] loss 1.083 || age f1 0.4052\n",
      "[Val_Total] Acc 87.54% || f1-score 0.7742\n",
      "[  Best   ] age_f1 0.4104 || total_f1 0.7796\n",
      "\n",
      "Epoch[7/50](50/267)\n",
      "     [ Age ] training loss 0.004596 || age f1 0.9946 || lr 5e-05\n",
      "     [Total] Acc 99.69% || f1-score 0.997\n",
      "Epoch[7/50](100/267)\n",
      "     [ Age ] training loss 0.003531 || age f1 0.996 || lr 5e-05\n",
      "     [Total] Acc 99.56% || f1-score 0.9968\n",
      "Epoch[7/50](150/267)\n",
      "     [ Age ] training loss 0.003722 || age f1 0.9953 || lr 5e-05\n",
      "     [Total] Acc 99.84% || f1-score 0.9979\n",
      "Epoch[7/50](200/267)\n",
      "     [ Age ] training loss 0.004018 || age f1 0.9966 || lr 5e-05\n",
      "     [Total] Acc 99.81% || f1-score 0.9985\n",
      "Epoch[7/50](250/267)\n",
      "     [ Age ] training loss 0.002579 || age f1 0.9975 || lr 5e-05\n",
      "     [Total] Acc 99.66% || f1-score 0.9962\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for Age || f1 : 0.4132! saving the best multi model..\n",
      "[ Val_Age ] loss 1.141 || age f1 0.4132\n",
      "[Val_Total] Acc 87.42% || f1-score 0.778\n",
      "[  Best   ] age_f1 0.4132 || total_f1 0.7796\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-65692360fdf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#         multi_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mage_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#         optimizer_multi.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "# best_val_multi_loss = np.inf\n",
    "# best_val_multi_f1 = 0\n",
    "best_val_age_loss = np.inf\n",
    "best_val_age_f1 = 0\n",
    "best_val_total_f1 = 0\n",
    "for epoch in range(config.epochs):\n",
    "    # train loop\n",
    "    model_multi.eval()\n",
    "    model_age.train()\n",
    "#     multi_loss_value = 0\n",
    "    age_loss_value = 0\n",
    "    matches = 0\n",
    "    label_list=[]\n",
    "    pred_list=[]\n",
    "    mask_label_list=[]\n",
    "    mask_pred_list=[]\n",
    "    age_label_list=[]\n",
    "    age_pred_list=[]\n",
    "    gender_label_list=[]\n",
    "    gender_pred_list=[]\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, (mask_labels, gender_labels, age_labels, multi_class_labels) = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        mask_labels = mask_labels.to(device)\n",
    "        gender_labels = gender_labels.to(device)\n",
    "        age_labels = age_labels.to(device)\n",
    "        multi_class_labels = multi_class_labels.to(device)\n",
    "\n",
    "#         optimizer_multi.zero_grad()\n",
    "        optimizer_age.zero_grad()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            mask_outs, gender_outs = model_multi(inputs)\n",
    "            mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "            mask_preds = mask_preds.detach().cpu()\n",
    "            gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "            gender_preds = gender_preds.detach().cpu()\n",
    "        \n",
    "        age_outs = model_age(inputs)\n",
    "        age_preds = torch.argmax(age_outs, dim=-1)\n",
    "        age_pred = age_preds.detach().cpu()\n",
    "        age_preds = age_preds.detach().cpu()\n",
    "        age_pred_list+=age_pred\n",
    "        age_preds = age_preds.apply_(AgeLabels.class2number)\n",
    "        \n",
    "        multi_preds = mask_preds * 6 + gender_preds * 3 + age_preds\n",
    "        multi_preds = multi_preds.to(device)\n",
    "        \n",
    "#         mask_loss = criterion_mask(mask_outs, mask_labels)\n",
    "#         gender_loss = criterion_gender(gender_outs, gender_labels)\n",
    "        \n",
    "#         multi_loss = mask_loss + gender_loss \n",
    "        age_loss = criterion_age(age_outs, age_labels)\n",
    "        \n",
    "#         multi_loss.backward()\n",
    "        age_loss.backward()\n",
    "\n",
    "#         optimizer_multi.step()\n",
    "        optimizer_age.step()\n",
    "        \n",
    "        label_list+=multi_class_labels.detach().cpu()\n",
    "        pred_list+=multi_preds.detach().cpu()\n",
    "        mask_label_list+=mask_labels.detach().cpu()\n",
    "        mask_pred_list+=mask_preds\n",
    "        age_label_list+=age_labels.detach().cpu()\n",
    "        gender_label_list+=gender_labels.detach().cpu()\n",
    "        gender_pred_list+=gender_preds\n",
    "\n",
    "#         multi_loss_value += multi_loss.item()\n",
    "        age_loss_value += age_loss.item()\n",
    "        matches += (multi_preds == multi_class_labels).sum().item()\n",
    "        if (idx + 1) % config.log_interval == 0:\n",
    "#             multi_train_loss = multi_loss_value / config.log_interval\n",
    "            age_train_loss = age_loss_value / config.log_interval\n",
    "            \n",
    "            total_train_acc = matches / config.batch_size / config.log_interval\n",
    "            total_train_f1 = f1_score(label_list, pred_list, average='macro')\n",
    "            \n",
    "            mask_f1 = f1_score(mask_label_list, mask_pred_list, average='macro')\n",
    "            age_f1 = f1_score(age_label_list, age_pred_list, average='macro')\n",
    "            gender_f1 = f1_score(gender_label_list, gender_pred_list, average='macro')\n",
    "            \n",
    "#             multi_current_lr = get_lr(optimizer_multi)\n",
    "            age_current_lr = get_lr(optimizer_age)\n",
    "            \n",
    "            print(f\"Epoch[{epoch}/{config.epochs}]({idx + 1}/{len(train_loader)})\")\n",
    "#             print(f\"     [Multi] training loss {multi_train_loss:4.4} || mask f1 {mask_f1:4.4} || gender f1 {gender_f1:4.4} || lr {multi_current_lr}\")\n",
    "            print(f\"     [ Age ] training loss {age_train_loss:4.4} || age f1 {age_f1:4.4} || lr {age_current_lr}\")\n",
    "            print(f\"     [Total] Acc {total_train_acc:4.2%} || f1-score {total_train_f1:4.4}\")\n",
    "#             logger.add_scalar(\"Train/multi_loss\", multi_train_loss, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/age_loss\", age_train_loss, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/total_accuracy\", total_train_acc, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/total_f1_score\", total_train_f1, epoch * len(train_loader) + idx)\n",
    "\n",
    "#             multi_loss_value = 0\n",
    "            age_loss_value = 0\n",
    "            matches = 0\n",
    "            label_list=[]\n",
    "            pred_list=[]\n",
    "            mask_label_list=[]\n",
    "            mask_pred_list=[]\n",
    "            age_label_list=[]\n",
    "            age_pred_list=[]\n",
    "            gender_label_list=[]\n",
    "            gender_pred_list=[]\n",
    "\n",
    "#     scheduler_multi.step()\n",
    "    scheduler_age.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"\\nCalculating validation results...\")\n",
    "        model_multi.eval()\n",
    "        model_age.eval()\n",
    "#         val_multi_loss_items = []\n",
    "        val_age_loss_items = []\n",
    "        val_acc_items = []\n",
    "        label_list=[]\n",
    "        pred_list=[]\n",
    "        mask_label_list=[]\n",
    "        mask_pred_list=[]\n",
    "        age_label_list=[]\n",
    "        age_pred_list=[]\n",
    "        gender_label_list=[]\n",
    "        gender_pred_list=[]\n",
    "        for val_batch in val_loader:\n",
    "            inputs, (mask_labels, gender_labels, age_labels, multi_class_labels) = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            mask_labels = mask_labels.to(device)\n",
    "            gender_labels = gender_labels.to(device)\n",
    "            age_labels = age_labels.to(device)\n",
    "            multi_class_labels = multi_class_labels.to(device)\n",
    "\n",
    "            mask_outs, gender_outs = model_multi(inputs)\n",
    "            mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "            mask_preds = mask_preds.detach().cpu()\n",
    "            gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "            gender_preds = gender_preds.detach().cpu()\n",
    "\n",
    "            age_outs = model_age(inputs)\n",
    "            age_preds = torch.argmax(age_outs, dim=-1)\n",
    "            age_pred = age_preds.detach().cpu()\n",
    "            age_preds = age_preds.detach().cpu()\n",
    "            age_pred_list+=age_pred\n",
    "            age_preds = age_preds.apply_(AgeLabels.class2number)\n",
    "\n",
    "            multi_preds = mask_preds * 6 + gender_preds * 3 + age_preds\n",
    "            multi_preds = multi_preds.to(device)\n",
    "\n",
    "#             mask_loss = criterion_mask(mask_outs, mask_labels)\n",
    "#             gender_loss = criterion_gender(gender_outs, gender_labels)\n",
    "\n",
    "#             multi_loss = mask_loss + gender_loss               \n",
    "            age_loss = criterion_age(age_outs, age_labels)      \n",
    "            \n",
    "            label_list+=multi_class_labels.detach().cpu()\n",
    "            pred_list+=multi_preds.detach().cpu()\n",
    "            mask_label_list+=mask_labels.detach().cpu()\n",
    "            mask_pred_list+=mask_preds\n",
    "            age_label_list+=age_labels.detach().cpu()\n",
    "            gender_label_list+=gender_labels.detach().cpu()\n",
    "            gender_pred_list+=gender_preds\n",
    "            \n",
    "            acc_item = (multi_class_labels == multi_preds).sum().item()\n",
    "#             val_multi_loss_items.append(multi_loss.item())\n",
    "            val_age_loss_items.append(age_loss.item())\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "#         val_multi_loss = float(np.sum(val_multi_loss_items) / len(val_loader))\n",
    "        val_age_loss = float(np.sum(val_age_loss_items) / len(val_loader))\n",
    "        \n",
    "        val_total_acc = float(np.sum(val_acc_items) / len(val_dataset))\n",
    "        val_total_f1= float(f1_score(label_list,pred_list,average=\"macro\"))\n",
    "        \n",
    "        val_mask_f1 = f1_score(mask_label_list, mask_pred_list, average='macro')\n",
    "        val_age_f1 = f1_score(age_label_list, age_pred_list, average='macro')\n",
    "        val_gender_f1 = f1_score(gender_label_list, gender_pred_list, average='macro')\n",
    "        val_multi_f1 = (val_mask_f1 + val_gender_f1) / 2  # mask, gender mean\n",
    "\n",
    "#         if val_multi_f1 > best_val_multi_f1:\n",
    "#             print(f\"New best model for Multi || f1 : {val_multi_f1:4.4}! saving the best multi model..\")\n",
    "#             torch.save(model_multi.state_dict(), f\"{save_dir}/best_multi.pth\")\n",
    "#             best_val_multi_f1 = val_multi_f1\n",
    "#             best_val_multi_loss = val_multi_loss\n",
    "        if val_age_f1 > best_val_age_f1:\n",
    "            print(f\"New best model for Age || f1 : {val_age_f1:4.4}! saving the best multi model..\")\n",
    "            torch.save(model_age.state_dict(), f\"{save_dir}/best_age.pth\")\n",
    "            best_val_age_f1 = val_age_f1\n",
    "            best_val_age_loss = val_age_loss\n",
    "        if val_total_f1 > best_val_total_f1:\n",
    "            print(f\"New best model for Total || f1 : {val_total_f1:4.4}! saving the best multi model..\")\n",
    "#             torch.save(model_multi.state_dict(), f\"{save_dir}/best_total_multi.pth\")\n",
    "            torch.save(model_age.state_dict(), f\"{save_dir}/best_total_age.pth\")\n",
    "            best_val_total_f1 = val_total_f1\n",
    "#         torch.save(model_multi.state_dict(), f\"{save_dir}/last_multi.pth\")\n",
    "        torch.save(model_age.state_dict(), f\"{save_dir}/last_age.pth\")\n",
    "        \n",
    "#         print(f\"[Val_Multi] loss {val_multi_loss:4.4} || mask f1 {val_mask_f1:4.4} || gender f1 {val_gender_f1:4.4}\")\n",
    "        print(f\"[ Val_Age ] loss {val_age_loss:4.4} || age f1 {val_age_f1:4.4}\")\n",
    "        print(f\"[Val_Total] Acc {val_total_acc:4.2%} || f1-score {val_total_f1:4.4}\")\n",
    "        print(f\"[  Best   ] age_f1 {best_val_age_f1:4.4} || total_f1 {best_val_total_f1:4.4}\")\n",
    "#         logger.add_scalar(\"Val/multi_loss\", val_multi_loss, epoch)\n",
    "        logger.add_scalar(\"Val/age_loss\", val_age_loss, epoch)\n",
    "        logger.add_scalar(\"Val/total_accuracy\", val_total_acc, epoch)\n",
    "        logger.add_scalar(\"Val/total_f1_score\", val_total_f1, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
