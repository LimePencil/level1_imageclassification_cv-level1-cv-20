{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, Subset, random_split, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config():\n",
    "    seed = 42\n",
    "    \n",
    "    # 데이터\n",
    "    data_dir = './input/data/train' #\n",
    "    resize = [224, 224]\n",
    "    val_ratio = 0.2\n",
    "    \n",
    "    # 학습 설정\n",
    "    epochs = 100 \n",
    "    batch_size = 64\n",
    "    valid_batch_size = 1000\n",
    "    lr = 1e-3\n",
    "    lr_decay_step = 20\n",
    "    log_interval = 50\n",
    "    \n",
    "    # 세이브 경로\n",
    "    save_dir = './exp'\n",
    "    \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 함수\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base setting\n",
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define transform (Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=(0.548, 0.504, 0.479)\n",
    "std=(0.237, 0.247, 0.246)\n",
    "train_transform = Compose([\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     ShiftScaleRotate(p=0.5),\n",
    "#     HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "#     RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#     GaussNoise(p=0.5),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)\n",
    "val_transform = Compose([\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base dataset class\n",
    "class BaseDataset(Dataset):\n",
    "    num_classes = 3*2*3\n",
    "    \n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.img_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset(img_dir = f'{config.data_dir}/images')\n",
    "\n",
    "n_val = int(len(dataset) * config.val_ratio)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_dataset.dataset.set_transform(train_transform)\n",
    "val_dataset.dataset.set_transform(val_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.valid_batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 24,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = models.vit_b_16(pretrained=True)\n",
    "        self.base_model.heads.head = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "num_classes = train_dataset.dataset.num_classes\n",
    "print(num_classes)\n",
    "model = BaseModel(num_classes=num_classes).to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss , metric , optimizer , scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=config.lr,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "scheduler = StepLR(optimizer, config.lr_decay_step, gamma=0.5)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path : exp\n"
     ]
    }
   ],
   "source": [
    "# 세이브 경로\n",
    "path = Path(config.save_dir)\n",
    "if (not path.exists()):\n",
    "    save_dir = str(path)\n",
    "else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    save_dir = f\"{path}{n}\"\n",
    "\n",
    "print(\"save path : \" + save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(log_dir=save_dir)\n",
    "with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(vars(config), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/100](50/237) || training loss 2.52 || training accuracy 19.59% || lr 0.001\n",
      "Epoch[0/100](100/237) || training loss 2.404 || training accuracy 19.66% || lr 0.001\n",
      "Epoch[0/100](150/237) || training loss 2.398 || training accuracy 20.28% || lr 0.001\n",
      "Epoch[0/100](200/237) || training loss 2.344 || training accuracy 22.75% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 23.70%! saving the best model..\n",
      "[Val] acc : 23.70%, loss:  2.3 || best acc : 23.70%, best loss:  2.3\n",
      "\n",
      "Epoch[1/100](50/237) || training loss 2.278 || training accuracy 25.69% || lr 0.001\n",
      "Epoch[1/100](100/237) || training loss 2.249 || training accuracy 28.28% || lr 0.001\n",
      "Epoch[1/100](150/237) || training loss 2.221 || training accuracy 26.78% || lr 0.001\n",
      "Epoch[1/100](200/237) || training loss 2.176 || training accuracy 28.34% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 29.31%! saving the best model..\n",
      "[Val] acc : 29.31%, loss:  2.3 || best acc : 29.31%, best loss:  2.3\n",
      "\n",
      "Epoch[2/100](50/237) || training loss 2.175 || training accuracy 29.47% || lr 0.001\n",
      "Epoch[2/100](100/237) || training loss 2.131 || training accuracy 30.38% || lr 0.001\n",
      "Epoch[2/100](150/237) || training loss 2.088 || training accuracy 30.91% || lr 0.001\n",
      "Epoch[2/100](200/237) || training loss 2.063 || training accuracy 30.97% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 25.50%, loss:  2.3 || best acc : 29.31%, best loss:  2.3\n",
      "\n",
      "Epoch[3/100](50/237) || training loss 2.061 || training accuracy 31.66% || lr 0.001\n",
      "Epoch[3/100](100/237) || training loss 2.005 || training accuracy 33.28% || lr 0.001\n",
      "Epoch[3/100](150/237) || training loss 1.878 || training accuracy 37.38% || lr 0.001\n",
      "Epoch[3/100](200/237) || training loss 1.86 || training accuracy 38.16% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 38.97%! saving the best model..\n",
      "[Val] acc : 38.97%, loss:  1.8 || best acc : 38.97%, best loss:  1.8\n",
      "\n",
      "Epoch[4/100](50/237) || training loss 1.744 || training accuracy 40.91% || lr 0.001\n",
      "Epoch[4/100](100/237) || training loss 1.728 || training accuracy 41.94% || lr 0.001\n",
      "Epoch[4/100](150/237) || training loss 1.629 || training accuracy 45.28% || lr 0.001\n",
      "Epoch[4/100](200/237) || training loss 1.75 || training accuracy 40.91% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 45.93%! saving the best model..\n",
      "[Val] acc : 45.93%, loss:  1.6 || best acc : 45.93%, best loss:  1.6\n",
      "\n",
      "Epoch[5/100](50/237) || training loss 1.566 || training accuracy 46.97% || lr 0.001\n",
      "Epoch[5/100](100/237) || training loss 1.557 || training accuracy 47.47% || lr 0.001\n",
      "Epoch[5/100](150/237) || training loss 1.463 || training accuracy 51.00% || lr 0.001\n",
      "Epoch[5/100](200/237) || training loss 1.452 || training accuracy 51.56% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 55.37%! saving the best model..\n",
      "[Val] acc : 55.37%, loss:  1.3 || best acc : 55.37%, best loss:  1.3\n",
      "\n",
      "Epoch[6/100](50/237) || training loss 1.358 || training accuracy 53.31% || lr 0.001\n",
      "Epoch[6/100](100/237) || training loss 1.389 || training accuracy 52.56% || lr 0.001\n",
      "Epoch[6/100](150/237) || training loss 1.345 || training accuracy 53.97% || lr 0.001\n",
      "Epoch[6/100](200/237) || training loss 1.329 || training accuracy 55.34% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 54.44%, loss:  1.4 || best acc : 55.37%, best loss:  1.3\n",
      "\n",
      "Epoch[7/100](50/237) || training loss 1.288 || training accuracy 55.19% || lr 0.001\n",
      "Epoch[7/100](100/237) || training loss 1.249 || training accuracy 57.84% || lr 0.001\n",
      "Epoch[7/100](150/237) || training loss 1.269 || training accuracy 57.16% || lr 0.001\n",
      "Epoch[7/100](200/237) || training loss 1.259 || training accuracy 57.63% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 56.48%! saving the best model..\n",
      "[Val] acc : 56.48%, loss:  1.3 || best acc : 56.48%, best loss:  1.3\n",
      "\n",
      "Epoch[8/100](50/237) || training loss 1.209 || training accuracy 58.19% || lr 0.001\n",
      "Epoch[8/100](100/237) || training loss 1.248 || training accuracy 57.63% || lr 0.001\n",
      "Epoch[8/100](150/237) || training loss 1.213 || training accuracy 59.00% || lr 0.001\n",
      "Epoch[8/100](200/237) || training loss 1.176 || training accuracy 59.38% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 58.57%! saving the best model..\n",
      "[Val] acc : 58.57%, loss:  1.3 || best acc : 58.57%, best loss:  1.3\n",
      "\n",
      "Epoch[9/100](50/237) || training loss 1.216 || training accuracy 59.38% || lr 0.001\n",
      "Epoch[9/100](100/237) || training loss 1.138 || training accuracy 61.09% || lr 0.001\n",
      "Epoch[9/100](150/237) || training loss 1.178 || training accuracy 59.38% || lr 0.001\n",
      "Epoch[9/100](200/237) || training loss 1.177 || training accuracy 60.12% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 57.35%, loss:  1.3 || best acc : 58.57%, best loss:  1.3\n",
      "\n",
      "Epoch[10/100](50/237) || training loss 1.131 || training accuracy 60.97% || lr 0.001\n",
      "Epoch[10/100](100/237) || training loss 1.145 || training accuracy 60.53% || lr 0.001\n",
      "Epoch[10/100](150/237) || training loss 1.149 || training accuracy 61.53% || lr 0.001\n",
      "Epoch[10/100](200/237) || training loss 1.121 || training accuracy 62.19% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 61.01%! saving the best model..\n",
      "[Val] acc : 61.01%, loss:  1.2 || best acc : 61.01%, best loss:  1.2\n",
      "\n",
      "Epoch[11/100](50/237) || training loss 1.088 || training accuracy 62.41% || lr 0.001\n",
      "Epoch[11/100](100/237) || training loss 1.059 || training accuracy 64.25% || lr 0.001\n",
      "Epoch[11/100](150/237) || training loss 1.121 || training accuracy 61.75% || lr 0.001\n",
      "Epoch[11/100](200/237) || training loss 1.074 || training accuracy 64.78% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 61.90%! saving the best model..\n",
      "[Val] acc : 61.90%, loss:  1.2 || best acc : 61.90%, best loss:  1.2\n",
      "\n",
      "Epoch[12/100](50/237) || training loss 1.055 || training accuracy 64.19% || lr 0.001\n",
      "Epoch[12/100](100/237) || training loss 1.086 || training accuracy 62.53% || lr 0.001\n",
      "Epoch[12/100](150/237) || training loss 1.106 || training accuracy 62.50% || lr 0.001\n",
      "Epoch[12/100](200/237) || training loss 1.071 || training accuracy 62.88% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 63.07%! saving the best model..\n",
      "[Val] acc : 63.07%, loss:  1.1 || best acc : 63.07%, best loss:  1.1\n",
      "\n",
      "Epoch[13/100](50/237) || training loss 1.02 || training accuracy 64.34% || lr 0.001\n",
      "Epoch[13/100](100/237) || training loss 1.045 || training accuracy 65.16% || lr 0.001\n",
      "Epoch[13/100](150/237) || training loss 1.041 || training accuracy 63.81% || lr 0.001\n",
      "Epoch[13/100](200/237) || training loss 1.039 || training accuracy 65.03% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 61.88%, loss:  1.1 || best acc : 63.07%, best loss:  1.1\n",
      "\n",
      "Epoch[14/100](50/237) || training loss 1.001 || training accuracy 65.31% || lr 0.001\n",
      "Epoch[14/100](100/237) || training loss 0.9614 || training accuracy 67.41% || lr 0.001\n",
      "Epoch[14/100](150/237) || training loss 0.9963 || training accuracy 65.88% || lr 0.001\n",
      "Epoch[14/100](200/237) || training loss 1.017 || training accuracy 65.84% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 62.51%, loss:  1.1 || best acc : 63.07%, best loss:  1.1\n",
      "\n",
      "Epoch[15/100](50/237) || training loss 0.9567 || training accuracy 66.69% || lr 0.001\n",
      "Epoch[15/100](100/237) || training loss 0.9948 || training accuracy 67.25% || lr 0.001\n",
      "Epoch[15/100](150/237) || training loss 1.026 || training accuracy 63.97% || lr 0.001\n",
      "Epoch[15/100](200/237) || training loss 0.9844 || training accuracy 66.66% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 64.26%! saving the best model..\n",
      "[Val] acc : 64.26%, loss:  1.0 || best acc : 64.26%, best loss:  1.0\n",
      "\n",
      "Epoch[16/100](50/237) || training loss 0.97 || training accuracy 67.41% || lr 0.001\n",
      "Epoch[16/100](100/237) || training loss 0.9678 || training accuracy 66.88% || lr 0.001\n",
      "Epoch[16/100](150/237) || training loss 0.9397 || training accuracy 67.59% || lr 0.001\n",
      "Epoch[16/100](200/237) || training loss 0.9825 || training accuracy 66.22% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 65.95%! saving the best model..\n",
      "[Val] acc : 65.95%, loss:  1.0 || best acc : 65.95%, best loss:  1.0\n",
      "\n",
      "Epoch[17/100](50/237) || training loss 0.8836 || training accuracy 70.78% || lr 0.001\n",
      "Epoch[17/100](100/237) || training loss 0.9796 || training accuracy 66.66% || lr 0.001\n",
      "Epoch[17/100](150/237) || training loss 0.957 || training accuracy 67.44% || lr 0.001\n",
      "Epoch[17/100](200/237) || training loss 0.9295 || training accuracy 67.78% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 66.59%! saving the best model..\n",
      "[Val] acc : 66.59%, loss:  1.0 || best acc : 66.59%, best loss:  1.0\n",
      "\n",
      "Epoch[18/100](50/237) || training loss 0.9248 || training accuracy 68.66% || lr 0.001\n",
      "Epoch[18/100](100/237) || training loss 0.9559 || training accuracy 67.06% || lr 0.001\n",
      "Epoch[18/100](150/237) || training loss 0.9587 || training accuracy 67.44% || lr 0.001\n",
      "Epoch[18/100](200/237) || training loss 0.8976 || training accuracy 69.00% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 68.92%! saving the best model..\n",
      "[Val] acc : 68.92%, loss: 0.94 || best acc : 68.92%, best loss: 0.94\n",
      "\n",
      "Epoch[19/100](50/237) || training loss 0.9091 || training accuracy 69.00% || lr 0.001\n",
      "Epoch[19/100](100/237) || training loss 0.8911 || training accuracy 69.88% || lr 0.001\n",
      "Epoch[19/100](150/237) || training loss 0.9231 || training accuracy 67.62% || lr 0.001\n",
      "Epoch[19/100](200/237) || training loss 0.9042 || training accuracy 68.66% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 64.87%, loss:  1.1 || best acc : 68.92%, best loss: 0.94\n",
      "\n",
      "Epoch[20/100](50/237) || training loss 0.824 || training accuracy 71.50% || lr 0.0005\n",
      "Epoch[20/100](100/237) || training loss 0.8159 || training accuracy 72.12% || lr 0.0005\n",
      "Epoch[20/100](150/237) || training loss 0.7929 || training accuracy 72.66% || lr 0.0005\n",
      "Epoch[20/100](200/237) || training loss 0.7852 || training accuracy 73.00% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 68.04%, loss: 0.93 || best acc : 68.92%, best loss: 0.93\n",
      "\n",
      "Epoch[21/100](50/237) || training loss 0.8072 || training accuracy 72.22% || lr 0.0005\n",
      "Epoch[21/100](100/237) || training loss 0.7753 || training accuracy 73.16% || lr 0.0005\n",
      "Epoch[21/100](150/237) || training loss 0.8139 || training accuracy 72.50% || lr 0.0005\n",
      "Epoch[21/100](200/237) || training loss 0.7492 || training accuracy 74.50% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 71.11%! saving the best model..\n",
      "[Val] acc : 71.11%, loss: 0.86 || best acc : 71.11%, best loss: 0.86\n",
      "\n",
      "Epoch[22/100](50/237) || training loss 0.7562 || training accuracy 74.25% || lr 0.0005\n",
      "Epoch[22/100](100/237) || training loss 0.7488 || training accuracy 73.38% || lr 0.0005\n",
      "Epoch[22/100](150/237) || training loss 0.7464 || training accuracy 74.25% || lr 0.0005\n",
      "Epoch[22/100](200/237) || training loss 0.788 || training accuracy 72.22% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 69.74%, loss: 0.88 || best acc : 71.11%, best loss: 0.86\n",
      "\n",
      "Epoch[23/100](50/237) || training loss 0.7578 || training accuracy 73.84% || lr 0.0005\n",
      "Epoch[23/100](100/237) || training loss 0.75 || training accuracy 74.28% || lr 0.0005\n",
      "Epoch[23/100](150/237) || training loss 0.7183 || training accuracy 74.72% || lr 0.0005\n",
      "Epoch[23/100](200/237) || training loss 0.7553 || training accuracy 74.31% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 68.99%, loss:  0.9 || best acc : 71.11%, best loss: 0.86\n",
      "\n",
      "Epoch[24/100](50/237) || training loss 0.7509 || training accuracy 74.41% || lr 0.0005\n",
      "Epoch[24/100](100/237) || training loss 0.7206 || training accuracy 75.72% || lr 0.0005\n",
      "Epoch[24/100](150/237) || training loss 0.7597 || training accuracy 73.28% || lr 0.0005\n",
      "Epoch[24/100](200/237) || training loss 0.732 || training accuracy 75.09% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.32%, loss: 0.86 || best acc : 71.11%, best loss: 0.86\n",
      "\n",
      "Epoch[25/100](50/237) || training loss 0.7075 || training accuracy 75.62% || lr 0.0005\n",
      "Epoch[25/100](100/237) || training loss 0.7436 || training accuracy 75.09% || lr 0.0005\n",
      "Epoch[25/100](150/237) || training loss 0.7402 || training accuracy 74.12% || lr 0.0005\n",
      "Epoch[25/100](200/237) || training loss 0.7265 || training accuracy 74.38% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 71.53%! saving the best model..\n",
      "[Val] acc : 71.53%, loss: 0.86 || best acc : 71.53%, best loss: 0.86\n",
      "\n",
      "Epoch[26/100](50/237) || training loss 0.7225 || training accuracy 74.66% || lr 0.0005\n",
      "Epoch[26/100](100/237) || training loss 0.6751 || training accuracy 76.44% || lr 0.0005\n",
      "Epoch[26/100](150/237) || training loss 0.7292 || training accuracy 74.75% || lr 0.0005\n",
      "Epoch[26/100](200/237) || training loss 0.707 || training accuracy 75.91% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.26%, loss:  0.9 || best acc : 71.53%, best loss: 0.86\n",
      "\n",
      "Epoch[27/100](50/237) || training loss 0.6869 || training accuracy 76.12% || lr 0.0005\n",
      "Epoch[27/100](100/237) || training loss 0.7203 || training accuracy 76.25% || lr 0.0005\n",
      "Epoch[27/100](150/237) || training loss 0.7151 || training accuracy 74.03% || lr 0.0005\n",
      "Epoch[27/100](200/237) || training loss 0.7217 || training accuracy 74.41% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.34%, loss: 0.87 || best acc : 71.53%, best loss: 0.86\n",
      "\n",
      "Epoch[28/100](50/237) || training loss 0.6862 || training accuracy 76.06% || lr 0.0005\n",
      "Epoch[28/100](100/237) || training loss 0.7269 || training accuracy 75.12% || lr 0.0005\n",
      "Epoch[28/100](150/237) || training loss 0.6634 || training accuracy 76.88% || lr 0.0005\n",
      "Epoch[28/100](200/237) || training loss 0.7103 || training accuracy 74.12% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 72.25%! saving the best model..\n",
      "[Val] acc : 72.25%, loss: 0.83 || best acc : 72.25%, best loss: 0.83\n",
      "\n",
      "Epoch[29/100](50/237) || training loss 0.651 || training accuracy 78.25% || lr 0.0005\n",
      "Epoch[29/100](100/237) || training loss 0.6675 || training accuracy 77.06% || lr 0.0005\n",
      "Epoch[29/100](150/237) || training loss 0.6754 || training accuracy 77.28% || lr 0.0005\n",
      "Epoch[29/100](200/237) || training loss 0.7168 || training accuracy 74.50% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 72.46%! saving the best model..\n",
      "[Val] acc : 72.46%, loss: 0.85 || best acc : 72.46%, best loss: 0.83\n",
      "\n",
      "Epoch[30/100](50/237) || training loss 0.6605 || training accuracy 76.38% || lr 0.0005\n",
      "Epoch[30/100](100/237) || training loss 0.6625 || training accuracy 76.75% || lr 0.0005\n",
      "Epoch[30/100](150/237) || training loss 0.6558 || training accuracy 77.19% || lr 0.0005\n",
      "Epoch[30/100](200/237) || training loss 0.6928 || training accuracy 75.94% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.82%, loss: 0.91 || best acc : 72.46%, best loss: 0.83\n",
      "\n",
      "Epoch[31/100](50/237) || training loss 0.6664 || training accuracy 76.69% || lr 0.0005\n",
      "Epoch[31/100](100/237) || training loss 0.6822 || training accuracy 76.25% || lr 0.0005\n",
      "Epoch[31/100](150/237) || training loss 0.6659 || training accuracy 76.56% || lr 0.0005\n",
      "Epoch[31/100](200/237) || training loss 0.6377 || training accuracy 78.09% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.98%, loss: 0.88 || best acc : 72.46%, best loss: 0.83\n",
      "\n",
      "Epoch[32/100](50/237) || training loss 0.6301 || training accuracy 77.22% || lr 0.0005\n",
      "Epoch[32/100](100/237) || training loss 0.6706 || training accuracy 76.16% || lr 0.0005\n",
      "Epoch[32/100](150/237) || training loss 0.623 || training accuracy 78.66% || lr 0.0005\n",
      "Epoch[32/100](200/237) || training loss 0.6601 || training accuracy 76.22% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 72.33%, loss: 0.81 || best acc : 72.46%, best loss: 0.81\n",
      "\n",
      "Epoch[33/100](50/237) || training loss 0.6273 || training accuracy 78.22% || lr 0.0005\n",
      "Epoch[33/100](100/237) || training loss 0.6211 || training accuracy 78.44% || lr 0.0005\n",
      "Epoch[33/100](150/237) || training loss 0.6422 || training accuracy 77.78% || lr 0.0005\n",
      "Epoch[33/100](200/237) || training loss 0.6192 || training accuracy 78.56% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 72.25%, loss: 0.81 || best acc : 72.46%, best loss: 0.81\n",
      "\n",
      "Epoch[34/100](50/237) || training loss 0.5923 || training accuracy 79.56% || lr 0.0005\n",
      "Epoch[34/100](100/237) || training loss 0.6243 || training accuracy 78.03% || lr 0.0005\n",
      "Epoch[34/100](150/237) || training loss 0.6124 || training accuracy 78.53% || lr 0.0005\n",
      "Epoch[34/100](200/237) || training loss 0.6523 || training accuracy 76.47% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 73.62%! saving the best model..\n",
      "[Val] acc : 73.62%, loss: 0.79 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[35/100](50/237) || training loss 0.5974 || training accuracy 79.38% || lr 0.0005\n",
      "Epoch[35/100](100/237) || training loss 0.5931 || training accuracy 79.31% || lr 0.0005\n",
      "Epoch[35/100](150/237) || training loss 0.6073 || training accuracy 78.75% || lr 0.0005\n",
      "Epoch[35/100](200/237) || training loss 0.6577 || training accuracy 76.75% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 72.01%, loss: 0.84 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[36/100](50/237) || training loss 0.599 || training accuracy 79.38% || lr 0.0005\n",
      "Epoch[36/100](100/237) || training loss 0.6452 || training accuracy 77.72% || lr 0.0005\n",
      "Epoch[36/100](150/237) || training loss 0.5835 || training accuracy 79.19% || lr 0.0005\n",
      "Epoch[36/100](200/237) || training loss 0.625 || training accuracy 78.25% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 71.32%, loss: 0.86 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[37/100](50/237) || training loss 0.5701 || training accuracy 79.66% || lr 0.0005\n",
      "Epoch[37/100](100/237) || training loss 0.5809 || training accuracy 80.25% || lr 0.0005\n",
      "Epoch[37/100](150/237) || training loss 0.5892 || training accuracy 78.91% || lr 0.0005\n",
      "Epoch[37/100](200/237) || training loss 0.6129 || training accuracy 77.66% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 73.23%, loss: 0.83 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[38/100](50/237) || training loss 0.5891 || training accuracy 79.41% || lr 0.0005\n",
      "Epoch[38/100](100/237) || training loss 0.5912 || training accuracy 79.69% || lr 0.0005\n",
      "Epoch[38/100](150/237) || training loss 0.5954 || training accuracy 78.84% || lr 0.0005\n",
      "Epoch[38/100](200/237) || training loss 0.5727 || training accuracy 79.81% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 71.19%, loss: 0.85 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[39/100](50/237) || training loss 0.62 || training accuracy 77.59% || lr 0.0005\n",
      "Epoch[39/100](100/237) || training loss 0.6073 || training accuracy 78.69% || lr 0.0005\n",
      "Epoch[39/100](150/237) || training loss 0.5403 || training accuracy 81.50% || lr 0.0005\n",
      "Epoch[39/100](200/237) || training loss 0.5642 || training accuracy 79.94% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 70.34%, loss: 0.91 || best acc : 73.62%, best loss: 0.79\n",
      "\n",
      "Epoch[40/100](50/237) || training loss 0.5227 || training accuracy 82.25% || lr 0.00025\n",
      "Epoch[40/100](100/237) || training loss 0.4975 || training accuracy 83.03% || lr 0.00025\n",
      "Epoch[40/100](150/237) || training loss 0.506 || training accuracy 82.16% || lr 0.00025\n",
      "Epoch[40/100](200/237) || training loss 0.5026 || training accuracy 82.31% || lr 0.00025\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 75.05%! saving the best model..\n",
      "[Val] acc : 75.05%, loss: 0.77 || best acc : 75.05%, best loss: 0.77\n",
      "\n",
      "Epoch[41/100](50/237) || training loss 0.4904 || training accuracy 83.16% || lr 0.00025\n",
      "Epoch[41/100](100/237) || training loss 0.4636 || training accuracy 83.81% || lr 0.00025\n",
      "Epoch[41/100](150/237) || training loss 0.4788 || training accuracy 83.09% || lr 0.00025\n",
      "Epoch[41/100](200/237) || training loss 0.5299 || training accuracy 81.44% || lr 0.00025\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 75.42%! saving the best model..\n",
      "[Val] acc : 75.42%, loss: 0.76 || best acc : 75.42%, best loss: 0.76\n",
      "\n",
      "Epoch[42/100](50/237) || training loss 0.4487 || training accuracy 84.56% || lr 0.00025\n",
      "Epoch[42/100](100/237) || training loss 0.4786 || training accuracy 83.78% || lr 0.00025\n",
      "Epoch[42/100](150/237) || training loss 0.4987 || training accuracy 81.84% || lr 0.00025\n",
      "Epoch[42/100](200/237) || training loss 0.4865 || training accuracy 82.75% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.08%, loss: 0.76 || best acc : 75.42%, best loss: 0.76\n",
      "\n",
      "Epoch[43/100](50/237) || training loss 0.4594 || training accuracy 83.50% || lr 0.00025\n",
      "Epoch[43/100](100/237) || training loss 0.4397 || training accuracy 84.34% || lr 0.00025\n",
      "Epoch[43/100](150/237) || training loss 0.4599 || training accuracy 83.91% || lr 0.00025\n",
      "Epoch[43/100](200/237) || training loss 0.5034 || training accuracy 82.12% || lr 0.00025\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 75.58%! saving the best model..\n",
      "[Val] acc : 75.58%, loss: 0.76 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[44/100](50/237) || training loss 0.4379 || training accuracy 85.81% || lr 0.00025\n",
      "Epoch[44/100](100/237) || training loss 0.4604 || training accuracy 83.19% || lr 0.00025\n",
      "Epoch[44/100](150/237) || training loss 0.4976 || training accuracy 82.78% || lr 0.00025\n",
      "Epoch[44/100](200/237) || training loss 0.4654 || training accuracy 83.12% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.89%, loss: 0.76 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[45/100](50/237) || training loss 0.4365 || training accuracy 84.16% || lr 0.00025\n",
      "Epoch[45/100](100/237) || training loss 0.47 || training accuracy 83.59% || lr 0.00025\n",
      "Epoch[45/100](150/237) || training loss 0.4726 || training accuracy 83.72% || lr 0.00025\n",
      "Epoch[45/100](200/237) || training loss 0.4465 || training accuracy 84.53% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.13%, loss: 0.79 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[46/100](50/237) || training loss 0.4413 || training accuracy 85.12% || lr 0.00025\n",
      "Epoch[46/100](100/237) || training loss 0.4562 || training accuracy 83.66% || lr 0.00025\n",
      "Epoch[46/100](150/237) || training loss 0.4596 || training accuracy 83.41% || lr 0.00025\n",
      "Epoch[46/100](200/237) || training loss 0.4479 || training accuracy 84.16% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.21%, loss: 0.78 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[47/100](50/237) || training loss 0.4255 || training accuracy 84.81% || lr 0.00025\n",
      "Epoch[47/100](100/237) || training loss 0.4629 || training accuracy 83.28% || lr 0.00025\n",
      "Epoch[47/100](150/237) || training loss 0.4435 || training accuracy 84.34% || lr 0.00025\n",
      "Epoch[47/100](200/237) || training loss 0.4354 || training accuracy 84.62% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.23%, loss: 0.79 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[48/100](50/237) || training loss 0.4488 || training accuracy 84.00% || lr 0.00025\n",
      "Epoch[48/100](100/237) || training loss 0.4315 || training accuracy 84.78% || lr 0.00025\n",
      "Epoch[48/100](150/237) || training loss 0.4256 || training accuracy 85.41% || lr 0.00025\n",
      "Epoch[48/100](200/237) || training loss 0.4304 || training accuracy 84.75% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.13%, loss: 0.78 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[49/100](50/237) || training loss 0.4377 || training accuracy 84.44% || lr 0.00025\n",
      "Epoch[49/100](100/237) || training loss 0.3963 || training accuracy 86.72% || lr 0.00025\n",
      "Epoch[49/100](150/237) || training loss 0.4174 || training accuracy 85.50% || lr 0.00025\n",
      "Epoch[49/100](200/237) || training loss 0.4356 || training accuracy 84.78% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.71%, loss: 0.79 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[50/100](50/237) || training loss 0.4471 || training accuracy 84.44% || lr 0.00025\n",
      "Epoch[50/100](100/237) || training loss 0.4189 || training accuracy 85.00% || lr 0.00025\n",
      "Epoch[50/100](150/237) || training loss 0.4202 || training accuracy 85.72% || lr 0.00025\n",
      "Epoch[50/100](200/237) || training loss 0.443 || training accuracy 84.19% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 73.54%, loss: 0.83 || best acc : 75.58%, best loss: 0.76\n",
      "\n",
      "Epoch[51/100](50/237) || training loss 0.4415 || training accuracy 83.88% || lr 0.00025\n",
      "Epoch[51/100](100/237) || training loss 0.4153 || training accuracy 85.28% || lr 0.00025\n",
      "Epoch[51/100](150/237) || training loss 0.4433 || training accuracy 84.59% || lr 0.00025\n",
      "Epoch[51/100](200/237) || training loss 0.4309 || training accuracy 84.47% || lr 0.00025\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 75.93%! saving the best model..\n",
      "[Val] acc : 75.93%, loss: 0.77 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[52/100](50/237) || training loss 0.3932 || training accuracy 85.81% || lr 0.00025\n",
      "Epoch[52/100](100/237) || training loss 0.4213 || training accuracy 85.81% || lr 0.00025\n",
      "Epoch[52/100](150/237) || training loss 0.4205 || training accuracy 85.69% || lr 0.00025\n",
      "Epoch[52/100](200/237) || training loss 0.3881 || training accuracy 86.22% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.50%, loss: 0.78 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[53/100](50/237) || training loss 0.3878 || training accuracy 86.25% || lr 0.00025\n",
      "Epoch[53/100](100/237) || training loss 0.426 || training accuracy 85.44% || lr 0.00025\n",
      "Epoch[53/100](150/237) || training loss 0.4057 || training accuracy 85.78% || lr 0.00025\n",
      "Epoch[53/100](200/237) || training loss 0.414 || training accuracy 85.31% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.68%, loss: 0.79 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[54/100](50/237) || training loss 0.3952 || training accuracy 86.06% || lr 0.00025\n",
      "Epoch[54/100](100/237) || training loss 0.4081 || training accuracy 85.00% || lr 0.00025\n",
      "Epoch[54/100](150/237) || training loss 0.3842 || training accuracy 86.62% || lr 0.00025\n",
      "Epoch[54/100](200/237) || training loss 0.4168 || training accuracy 84.97% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.26%, loss: 0.79 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[55/100](50/237) || training loss 0.3718 || training accuracy 86.75% || lr 0.00025\n",
      "Epoch[55/100](100/237) || training loss 0.3994 || training accuracy 85.62% || lr 0.00025\n",
      "Epoch[55/100](150/237) || training loss 0.3742 || training accuracy 87.16% || lr 0.00025\n",
      "Epoch[55/100](200/237) || training loss 0.4217 || training accuracy 85.22% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.66%, loss: 0.78 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[56/100](50/237) || training loss 0.3815 || training accuracy 86.84% || lr 0.00025\n",
      "Epoch[56/100](100/237) || training loss 0.3771 || training accuracy 87.03% || lr 0.00025\n",
      "Epoch[56/100](150/237) || training loss 0.3894 || training accuracy 86.12% || lr 0.00025\n",
      "Epoch[56/100](200/237) || training loss 0.3802 || training accuracy 86.66% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.15%, loss: 0.83 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[57/100](50/237) || training loss 0.3832 || training accuracy 86.44% || lr 0.00025\n",
      "Epoch[57/100](100/237) || training loss 0.4142 || training accuracy 85.62% || lr 0.00025\n",
      "Epoch[57/100](150/237) || training loss 0.3589 || training accuracy 87.00% || lr 0.00025\n",
      "Epoch[57/100](200/237) || training loss 0.3836 || training accuracy 85.88% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.52%, loss: 0.81 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[58/100](50/237) || training loss 0.3852 || training accuracy 86.09% || lr 0.00025\n",
      "Epoch[58/100](100/237) || training loss 0.3691 || training accuracy 86.94% || lr 0.00025\n",
      "Epoch[58/100](150/237) || training loss 0.3913 || training accuracy 86.78% || lr 0.00025\n",
      "Epoch[58/100](200/237) || training loss 0.3951 || training accuracy 85.91% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.34%, loss: 0.84 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[59/100](50/237) || training loss 0.3574 || training accuracy 86.84% || lr 0.00025\n",
      "Epoch[59/100](100/237) || training loss 0.3324 || training accuracy 88.66% || lr 0.00025\n",
      "Epoch[59/100](150/237) || training loss 0.3816 || training accuracy 86.22% || lr 0.00025\n",
      "Epoch[59/100](200/237) || training loss 0.3846 || training accuracy 86.38% || lr 0.00025\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.40%, loss: 0.79 || best acc : 75.93%, best loss: 0.76\n",
      "\n",
      "Epoch[60/100](50/237) || training loss 0.323 || training accuracy 89.12% || lr 0.000125\n",
      "Epoch[60/100](100/237) || training loss 0.3039 || training accuracy 89.25% || lr 0.000125\n",
      "Epoch[60/100](150/237) || training loss 0.3004 || training accuracy 89.88% || lr 0.000125\n",
      "Epoch[60/100](200/237) || training loss 0.3213 || training accuracy 88.62% || lr 0.000125\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 76.16%! saving the best model..\n",
      "[Val] acc : 76.16%, loss: 0.77 || best acc : 76.16%, best loss: 0.76\n",
      "\n",
      "Epoch[61/100](50/237) || training loss 0.2894 || training accuracy 90.00% || lr 0.000125\n",
      "Epoch[61/100](100/237) || training loss 0.2966 || training accuracy 90.12% || lr 0.000125\n",
      "Epoch[61/100](150/237) || training loss 0.3148 || training accuracy 89.44% || lr 0.000125\n",
      "Epoch[61/100](200/237) || training loss 0.3043 || training accuracy 89.22% || lr 0.000125\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 77.06%! saving the best model..\n",
      "[Val] acc : 77.06%, loss: 0.76 || best acc : 77.06%, best loss: 0.76\n",
      "\n",
      "Epoch[62/100](50/237) || training loss 0.296 || training accuracy 90.06% || lr 0.000125\n",
      "Epoch[62/100](100/237) || training loss 0.2841 || training accuracy 90.22% || lr 0.000125\n",
      "Epoch[62/100](150/237) || training loss 0.316 || training accuracy 89.06% || lr 0.000125\n",
      "Epoch[62/100](200/237) || training loss 0.2968 || training accuracy 89.94% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.38%, loss: 0.78 || best acc : 77.06%, best loss: 0.76\n",
      "\n",
      "Epoch[63/100](50/237) || training loss 0.2773 || training accuracy 90.22% || lr 0.000125\n",
      "Epoch[63/100](100/237) || training loss 0.2993 || training accuracy 89.91% || lr 0.000125\n",
      "Epoch[63/100](150/237) || training loss 0.2924 || training accuracy 89.72% || lr 0.000125\n",
      "Epoch[63/100](200/237) || training loss 0.3079 || training accuracy 89.12% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.22%, loss: 0.79 || best acc : 77.06%, best loss: 0.76\n",
      "\n",
      "Epoch[64/100](50/237) || training loss 0.2923 || training accuracy 90.38% || lr 0.000125\n",
      "Epoch[64/100](100/237) || training loss 0.2885 || training accuracy 89.91% || lr 0.000125\n",
      "Epoch[64/100](150/237) || training loss 0.3127 || training accuracy 89.06% || lr 0.000125\n",
      "Epoch[64/100](200/237) || training loss 0.2944 || training accuracy 89.78% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.64%, loss: 0.81 || best acc : 77.06%, best loss: 0.76\n",
      "\n",
      "Epoch[65/100](50/237) || training loss 0.2766 || training accuracy 89.81% || lr 0.000125\n",
      "Epoch[65/100](100/237) || training loss 0.3016 || training accuracy 89.75% || lr 0.000125\n",
      "Epoch[65/100](150/237) || training loss 0.297 || training accuracy 89.41% || lr 0.000125\n",
      "Epoch[65/100](200/237) || training loss 0.2864 || training accuracy 90.22% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.59%, loss:  0.8 || best acc : 77.06%, best loss: 0.76\n",
      "\n",
      "Epoch[66/100](50/237) || training loss 0.2649 || training accuracy 91.09% || lr 0.000125\n",
      "Epoch[66/100](100/237) || training loss 0.287 || training accuracy 90.22% || lr 0.000125\n",
      "Epoch[66/100](150/237) || training loss 0.2883 || training accuracy 89.34% || lr 0.000125\n",
      "Epoch[66/100](200/237) || training loss 0.2888 || training accuracy 89.31% || lr 0.000125\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 77.22%! saving the best model..\n",
      "[Val] acc : 77.22%, loss:  0.8 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[67/100](50/237) || training loss 0.2677 || training accuracy 90.94% || lr 0.000125\n",
      "Epoch[67/100](100/237) || training loss 0.284 || training accuracy 90.75% || lr 0.000125\n",
      "Epoch[67/100](150/237) || training loss 0.2764 || training accuracy 90.59% || lr 0.000125\n",
      "Epoch[67/100](200/237) || training loss 0.2784 || training accuracy 90.50% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.56%, loss: 0.81 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[68/100](50/237) || training loss 0.2725 || training accuracy 90.47% || lr 0.000125\n",
      "Epoch[68/100](100/237) || training loss 0.2974 || training accuracy 90.22% || lr 0.000125\n",
      "Epoch[68/100](150/237) || training loss 0.271 || training accuracy 90.66% || lr 0.000125\n",
      "Epoch[68/100](200/237) || training loss 0.2788 || training accuracy 90.25% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.75%, loss:  0.8 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[69/100](50/237) || training loss 0.2597 || training accuracy 91.41% || lr 0.000125\n",
      "Epoch[69/100](100/237) || training loss 0.2578 || training accuracy 91.38% || lr 0.000125\n",
      "Epoch[69/100](150/237) || training loss 0.287 || training accuracy 90.19% || lr 0.000125\n",
      "Epoch[69/100](200/237) || training loss 0.2866 || training accuracy 90.28% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.71%, loss: 0.85 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[70/100](50/237) || training loss 0.2744 || training accuracy 90.78% || lr 0.000125\n",
      "Epoch[70/100](100/237) || training loss 0.2342 || training accuracy 92.06% || lr 0.000125\n",
      "Epoch[70/100](150/237) || training loss 0.2632 || training accuracy 91.16% || lr 0.000125\n",
      "Epoch[70/100](200/237) || training loss 0.2707 || training accuracy 91.00% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.69%, loss: 0.83 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[71/100](50/237) || training loss 0.2792 || training accuracy 90.88% || lr 0.000125\n",
      "Epoch[71/100](100/237) || training loss 0.2538 || training accuracy 91.06% || lr 0.000125\n",
      "Epoch[71/100](150/237) || training loss 0.2666 || training accuracy 90.97% || lr 0.000125\n",
      "Epoch[71/100](200/237) || training loss 0.2791 || training accuracy 90.34% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.77%, loss: 0.86 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[72/100](50/237) || training loss 0.2542 || training accuracy 91.50% || lr 0.000125\n",
      "Epoch[72/100](100/237) || training loss 0.2508 || training accuracy 91.38% || lr 0.000125\n",
      "Epoch[72/100](150/237) || training loss 0.2614 || training accuracy 91.56% || lr 0.000125\n",
      "Epoch[72/100](200/237) || training loss 0.2735 || training accuracy 90.28% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.40%, loss: 0.83 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[73/100](50/237) || training loss 0.259 || training accuracy 90.50% || lr 0.000125\n",
      "Epoch[73/100](100/237) || training loss 0.2389 || training accuracy 92.38% || lr 0.000125\n",
      "Epoch[73/100](150/237) || training loss 0.2625 || training accuracy 90.72% || lr 0.000125\n",
      "Epoch[73/100](200/237) || training loss 0.266 || training accuracy 90.16% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.53%, loss: 0.84 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[74/100](50/237) || training loss 0.2279 || training accuracy 91.94% || lr 0.000125\n",
      "Epoch[74/100](100/237) || training loss 0.2275 || training accuracy 92.03% || lr 0.000125\n",
      "Epoch[74/100](150/237) || training loss 0.2586 || training accuracy 91.16% || lr 0.000125\n",
      "Epoch[74/100](200/237) || training loss 0.2673 || training accuracy 91.00% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.22%, loss: 0.84 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[75/100](50/237) || training loss 0.2283 || training accuracy 92.91% || lr 0.000125\n",
      "Epoch[75/100](100/237) || training loss 0.252 || training accuracy 91.62% || lr 0.000125\n",
      "Epoch[75/100](150/237) || training loss 0.2453 || training accuracy 91.53% || lr 0.000125\n",
      "Epoch[75/100](200/237) || training loss 0.2448 || training accuracy 90.97% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.19%, loss: 0.89 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[76/100](50/237) || training loss 0.2386 || training accuracy 92.25% || lr 0.000125\n",
      "Epoch[76/100](100/237) || training loss 0.2205 || training accuracy 92.59% || lr 0.000125\n",
      "Epoch[76/100](150/237) || training loss 0.2592 || training accuracy 91.16% || lr 0.000125\n",
      "Epoch[76/100](200/237) || training loss 0.2431 || training accuracy 91.72% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.30%, loss: 0.85 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[77/100](50/237) || training loss 0.249 || training accuracy 91.28% || lr 0.000125\n",
      "Epoch[77/100](100/237) || training loss 0.2246 || training accuracy 92.25% || lr 0.000125\n",
      "Epoch[77/100](150/237) || training loss 0.245 || training accuracy 91.72% || lr 0.000125\n",
      "Epoch[77/100](200/237) || training loss 0.2148 || training accuracy 92.94% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.83%, loss: 0.84 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[78/100](50/237) || training loss 0.2276 || training accuracy 92.62% || lr 0.000125\n",
      "Epoch[78/100](100/237) || training loss 0.2388 || training accuracy 91.84% || lr 0.000125\n",
      "Epoch[78/100](150/237) || training loss 0.2401 || training accuracy 91.47% || lr 0.000125\n",
      "Epoch[78/100](200/237) || training loss 0.2709 || training accuracy 90.94% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.11%, loss: 0.85 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[79/100](50/237) || training loss 0.2123 || training accuracy 93.34% || lr 0.000125\n",
      "Epoch[79/100](100/237) || training loss 0.2217 || training accuracy 93.00% || lr 0.000125\n",
      "Epoch[79/100](150/237) || training loss 0.2286 || training accuracy 92.12% || lr 0.000125\n",
      "Epoch[79/100](200/237) || training loss 0.2632 || training accuracy 90.72% || lr 0.000125\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.32%, loss: 0.87 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[80/100](50/237) || training loss 0.1864 || training accuracy 94.03% || lr 6.25e-05\n",
      "Epoch[80/100](100/237) || training loss 0.1925 || training accuracy 93.84% || lr 6.25e-05\n",
      "Epoch[80/100](150/237) || training loss 0.2091 || training accuracy 93.00% || lr 6.25e-05\n",
      "Epoch[80/100](200/237) || training loss 0.1994 || training accuracy 93.47% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.51%, loss: 0.86 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[81/100](50/237) || training loss 0.1786 || training accuracy 94.56% || lr 6.25e-05\n",
      "Epoch[81/100](100/237) || training loss 0.1866 || training accuracy 94.16% || lr 6.25e-05\n",
      "Epoch[81/100](150/237) || training loss 0.2049 || training accuracy 93.53% || lr 6.25e-05\n",
      "Epoch[81/100](200/237) || training loss 0.2004 || training accuracy 93.59% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.64%, loss: 0.86 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[82/100](50/237) || training loss 0.1763 || training accuracy 94.75% || lr 6.25e-05\n",
      "Epoch[82/100](100/237) || training loss 0.187 || training accuracy 94.50% || lr 6.25e-05\n",
      "Epoch[82/100](150/237) || training loss 0.1787 || training accuracy 94.38% || lr 6.25e-05\n",
      "Epoch[82/100](200/237) || training loss 0.1969 || training accuracy 94.03% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.67%, loss: 0.88 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[83/100](50/237) || training loss 0.1675 || training accuracy 94.72% || lr 6.25e-05\n",
      "Epoch[83/100](100/237) || training loss 0.1983 || training accuracy 93.88% || lr 6.25e-05\n",
      "Epoch[83/100](150/237) || training loss 0.1914 || training accuracy 94.12% || lr 6.25e-05\n",
      "Epoch[83/100](200/237) || training loss 0.1942 || training accuracy 93.50% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.38%, loss: 0.91 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[84/100](50/237) || training loss 0.181 || training accuracy 94.53% || lr 6.25e-05\n",
      "Epoch[84/100](100/237) || training loss 0.1718 || training accuracy 94.91% || lr 6.25e-05\n",
      "Epoch[84/100](150/237) || training loss 0.1761 || training accuracy 94.09% || lr 6.25e-05\n",
      "Epoch[84/100](200/237) || training loss 0.2051 || training accuracy 93.66% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.56%, loss: 0.89 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[85/100](50/237) || training loss 0.1811 || training accuracy 94.56% || lr 6.25e-05\n",
      "Epoch[85/100](100/237) || training loss 0.1822 || training accuracy 94.53% || lr 6.25e-05\n",
      "Epoch[85/100](150/237) || training loss 0.1989 || training accuracy 93.91% || lr 6.25e-05\n",
      "Epoch[85/100](200/237) || training loss 0.1763 || training accuracy 94.06% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.56%, loss: 0.89 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[86/100](50/237) || training loss 0.1499 || training accuracy 95.97% || lr 6.25e-05\n",
      "Epoch[86/100](100/237) || training loss 0.1869 || training accuracy 94.31% || lr 6.25e-05\n",
      "Epoch[86/100](150/237) || training loss 0.1984 || training accuracy 93.16% || lr 6.25e-05\n",
      "Epoch[86/100](200/237) || training loss 0.1873 || training accuracy 93.88% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.35%, loss: 0.89 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[87/100](50/237) || training loss 0.1711 || training accuracy 94.75% || lr 6.25e-05\n",
      "Epoch[87/100](100/237) || training loss 0.1698 || training accuracy 94.91% || lr 6.25e-05\n",
      "Epoch[87/100](150/237) || training loss 0.1758 || training accuracy 94.38% || lr 6.25e-05\n",
      "Epoch[87/100](200/237) || training loss 0.1921 || training accuracy 94.06% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.40%, loss:  0.9 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[88/100](50/237) || training loss 0.173 || training accuracy 95.12% || lr 6.25e-05\n",
      "Epoch[88/100](100/237) || training loss 0.1718 || training accuracy 94.56% || lr 6.25e-05\n",
      "Epoch[88/100](150/237) || training loss 0.1642 || training accuracy 94.66% || lr 6.25e-05\n",
      "Epoch[88/100](200/237) || training loss 0.1755 || training accuracy 94.47% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.29%, loss: 0.94 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[89/100](50/237) || training loss 0.1591 || training accuracy 95.44% || lr 6.25e-05\n",
      "Epoch[89/100](100/237) || training loss 0.171 || training accuracy 94.94% || lr 6.25e-05\n",
      "Epoch[89/100](150/237) || training loss 0.1733 || training accuracy 94.38% || lr 6.25e-05\n",
      "Epoch[89/100](200/237) || training loss 0.1764 || training accuracy 94.22% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.61%, loss: 0.91 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[90/100](50/237) || training loss 0.167 || training accuracy 94.88% || lr 6.25e-05\n",
      "Epoch[90/100](100/237) || training loss 0.1712 || training accuracy 94.56% || lr 6.25e-05\n",
      "Epoch[90/100](150/237) || training loss 0.1677 || training accuracy 94.94% || lr 6.25e-05\n",
      "Epoch[90/100](200/237) || training loss 0.1707 || training accuracy 94.97% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.88%, loss: 0.92 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[91/100](50/237) || training loss 0.1648 || training accuracy 94.91% || lr 6.25e-05\n",
      "Epoch[91/100](100/237) || training loss 0.1599 || training accuracy 95.16% || lr 6.25e-05\n",
      "Epoch[91/100](150/237) || training loss 0.1657 || training accuracy 94.69% || lr 6.25e-05\n",
      "Epoch[91/100](200/237) || training loss 0.1759 || training accuracy 94.50% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.46%, loss: 0.94 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[92/100](50/237) || training loss 0.1764 || training accuracy 94.59% || lr 6.25e-05\n",
      "Epoch[92/100](100/237) || training loss 0.1444 || training accuracy 96.03% || lr 6.25e-05\n",
      "Epoch[92/100](150/237) || training loss 0.1705 || training accuracy 94.81% || lr 6.25e-05\n",
      "Epoch[92/100](200/237) || training loss 0.1793 || training accuracy 94.12% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.48%, loss: 0.94 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[93/100](50/237) || training loss 0.166 || training accuracy 95.22% || lr 6.25e-05\n",
      "Epoch[93/100](100/237) || training loss 0.1645 || training accuracy 94.97% || lr 6.25e-05\n",
      "Epoch[93/100](150/237) || training loss 0.1588 || training accuracy 95.25% || lr 6.25e-05\n",
      "Epoch[93/100](200/237) || training loss 0.1645 || training accuracy 94.88% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.75%, loss: 0.94 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[94/100](50/237) || training loss 0.1605 || training accuracy 95.44% || lr 6.25e-05\n",
      "Epoch[94/100](100/237) || training loss 0.1499 || training accuracy 95.47% || lr 6.25e-05\n",
      "Epoch[94/100](150/237) || training loss 0.161 || training accuracy 95.00% || lr 6.25e-05\n",
      "Epoch[94/100](200/237) || training loss 0.1692 || training accuracy 94.81% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.53%, loss: 0.95 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[95/100](50/237) || training loss 0.1506 || training accuracy 95.72% || lr 6.25e-05\n",
      "Epoch[95/100](100/237) || training loss 0.1537 || training accuracy 95.66% || lr 6.25e-05\n",
      "Epoch[95/100](150/237) || training loss 0.1699 || training accuracy 94.66% || lr 6.25e-05\n",
      "Epoch[95/100](200/237) || training loss 0.1635 || training accuracy 94.44% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.61%, loss: 0.96 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[96/100](50/237) || training loss 0.1542 || training accuracy 95.41% || lr 6.25e-05\n",
      "Epoch[96/100](100/237) || training loss 0.153 || training accuracy 95.16% || lr 6.25e-05\n",
      "Epoch[96/100](150/237) || training loss 0.1598 || training accuracy 95.28% || lr 6.25e-05\n",
      "Epoch[96/100](200/237) || training loss 0.154 || training accuracy 95.19% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.11%, loss: 0.97 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[97/100](50/237) || training loss 0.169 || training accuracy 94.50% || lr 6.25e-05\n",
      "Epoch[97/100](100/237) || training loss 0.1482 || training accuracy 95.78% || lr 6.25e-05\n",
      "Epoch[97/100](150/237) || training loss 0.1573 || training accuracy 95.22% || lr 6.25e-05\n",
      "Epoch[97/100](200/237) || training loss 0.1675 || training accuracy 94.59% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 75.79%, loss: 0.98 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[98/100](50/237) || training loss 0.1432 || training accuracy 95.84% || lr 6.25e-05\n",
      "Epoch[98/100](100/237) || training loss 0.1581 || training accuracy 95.06% || lr 6.25e-05\n",
      "Epoch[98/100](150/237) || training loss 0.1427 || training accuracy 95.59% || lr 6.25e-05\n",
      "Epoch[98/100](200/237) || training loss 0.1534 || training accuracy 95.19% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.43%, loss: 0.97 || best acc : 77.22%, best loss: 0.76\n",
      "\n",
      "Epoch[99/100](50/237) || training loss 0.1424 || training accuracy 95.75% || lr 6.25e-05\n",
      "Epoch[99/100](100/237) || training loss 0.1425 || training accuracy 96.28% || lr 6.25e-05\n",
      "Epoch[99/100](150/237) || training loss 0.1376 || training accuracy 96.16% || lr 6.25e-05\n",
      "Epoch[99/100](200/237) || training loss 0.1606 || training accuracy 95.22% || lr 6.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 76.38%, loss: 0.96 || best acc : 77.22%, best loss: 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(config.epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % config.log_interval == 0:\n",
    "            train_loss = loss_value / config.log_interval\n",
    "            train_acc = matches / config.batch_size / config.log_interval\n",
    "            current_lr = get_lr(optimizer)\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{config.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "            logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_dataset)\n",
    "        best_val_loss = min(best_val_loss, val_loss)\n",
    "        if val_acc > best_val_acc:\n",
    "            print(f\"New best model for val accuracy : {val_acc:4.2%}! saving the best model..\")\n",
    "            torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "            best_val_acc = val_acc\n",
    "        torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )\n",
    "        logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "        logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import vit_b_16\n",
    "# model = models.vit_b_16(pretrained=True)\n",
    "# model.heads.head = nn.Linear(in_features=768, out_features=18, bias=True)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
