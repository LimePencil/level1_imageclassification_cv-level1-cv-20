{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, ExponentialLR\n",
    "from torch.utils.data import Dataset, Subset, random_split, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config():\n",
    "    seed = 42\n",
    "    \n",
    "    # 데이터\n",
    "#     data_dir = './face_input/train' #\n",
    "    data_dir = './input/data/train'\n",
    "    resize = [224, 224]\n",
    "    val_ratio = 0.2\n",
    "    \n",
    "    # 학습 설정\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "#     batch_size = 16\n",
    "    valid_batch_size = 1000\n",
    "    lr = 1e-4\n",
    "    lr_decay_step = 5\n",
    "    log_interval = 50\n",
    "    patience = 10 # early stop\n",
    "    n_splits = 7 # k - fold\n",
    "    \n",
    "    # 세이브 경로\n",
    "    save_dir = './kfoldEnsemble_exp'\n",
    "    \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 함수\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base setting\n",
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define transform (Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=(0.548, 0.504, 0.479)\n",
    "std=(0.237, 0.247, 0.246)\n",
    "train_transform = Compose([\n",
    "    CenterCrop(height=480, width=320),\n",
    "    HorizontalFlip(p=0.5),\n",
    "#     ShiftScaleRotate(p=0.5),\n",
    "    HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    RandomScale(scale_limit=0.1, interpolation=cv2.INTER_LINEAR, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "    GaussNoise(p=0.5),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0, interpolation=cv2.INTER_LINEAR),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)\n",
    "val_transform = Compose([\n",
    "    CenterCrop(height=480, width=320),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base dataset class\n",
    "class newBaseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, indices, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "        self._file_names = {\n",
    "            \"mask1\": MaskLabels.MASK,\n",
    "            \"mask2\": MaskLabels.MASK,\n",
    "            \"mask3\": MaskLabels.MASK,\n",
    "            \"mask4\": MaskLabels.MASK,\n",
    "            \"mask5\": MaskLabels.MASK,\n",
    "            \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "            \"normal\": MaskLabels.NORMAL\n",
    "        }\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        csv_path = os.path.join(self.img_dir, 'train.csv')\n",
    "        csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        csv_data = csv_data.loc[self.indices]\n",
    "        csv_data_list = list(csv_data.values)\n",
    "        cnt = 0\n",
    "        for id, gender, _, age, path in csv_data_list:\n",
    "            img_folder = os.path.join(self.img_dir, 'images', path)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "                    \n",
    "                img_path = os.path.join(img_folder, file_name)  # (data_path, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, (mask_label, gender_label, age_label, multi_class_label) # multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    \n",
    "    # 이외 utils\n",
    "#     @staticmethod\n",
    "#     def split_data(val_ratio):\n",
    "#         return val\n",
    "#     @staticmethod\n",
    "#     def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "#         return mask_label * 6 + gender_label * 3 + age_label\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "#         mask_label = (multi_class_label // 6) % 3\n",
    "#         gender_label = (multi_class_label // 3) % 2\n",
    "#         age_label = multi_class_label % 3\n",
    "#         return mask_label, gender_label, age_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(ImbalancedDatasetSampler):\n",
    "    def _get_labels(self, dataset):\n",
    "        return dataset.age_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(train_idx, valid_idx):\n",
    "    train_dataset = newBaseDataset(img_dir = config.data_dir, indices = train_idx)\n",
    "    val_dataset = newBaseDataset(img_dir = config.data_dir, indices = valid_idx)\n",
    "    train_dataset.set_transform(train_transform)\n",
    "    val_dataset.set_transform(val_transform)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        sampler=Sampler(train_dataset),\n",
    "#         shuffle=True,\n",
    "#         pin_memory=use_cuda\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.valid_batch_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=False,\n",
    "#         pin_memory=use_cuda\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaseModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.vit_b_16(pretrained=True)\n",
    "#         self.base_model.heads.head = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResnextModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.resnext50_32x4d(pretrained=True)\n",
    "#         self.base_model.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(in_features=1000, out_features=num_classes, bias=True)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Resnext101Model(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.DEFAULT)\n",
    "#         self.base_model.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "#             nn.ELU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(in_features=1000, out_features=num_classes, bias=True)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class ResnextMultiheadModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.base_model.fc = Identity()\n",
    "\n",
    "        self.fc_mask_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "        )\n",
    "        self.fc_age_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "        )\n",
    "        self.fc_gender_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=2, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        mask = self.fc_mask_classifier(x)\n",
    "        age = self.fc_age_classifier(x)\n",
    "        gender = self.fc_gender_classifier(x)\n",
    "        return mask, age, gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResnextMultiheadModel().to(device)\n",
    "# model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss , metric , optimizer , scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = FocalLoss()\n",
    "# optimizer = Adam(\n",
    "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#     lr=config.lr,\n",
    "#     weight_decay=5e-4\n",
    "# )\n",
    "# optimizer = SGD(\n",
    "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#     lr=config.lr,\n",
    "#     momentum=0.9,\n",
    "#     nesterov=True\n",
    "# )\n",
    "# optimizer = RMSprop(\n",
    "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#     lr=config.lr,\n",
    "#     weight_decay=5e-4,\n",
    "#     momentum=0.9\n",
    "# )\n",
    "# scheduler = StepLR(optimizer, config.lr_decay_step, gamma=0.5)\n",
    "# -- scheduler: ReduceLROnPlateau\n",
    "# 성능이 향상되지 않을 때 learning rate를 줄입니다. patience=10은 10회 동안 성능 향상이 없을 경우입니다.\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "# -- scheduler: CosineAnnealingLR\n",
    "# CosineAnnealing은 learning rate를 cosine 그래프처럼 변화시킵니다.\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path : kfoldEnsemble_exp4\n"
     ]
    }
   ],
   "source": [
    "# 세이브 경로\n",
    "path = Path(config.save_dir)\n",
    "if (not path.exists()):\n",
    "    save_dir = str(path)\n",
    "else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    save_dir = f\"{path}{n}\"\n",
    "\n",
    "print(\"save path : \" + save_dir)\n",
    "os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = SummaryWriter(log_dir=save_dir)\n",
    "# with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "#     json.dump(vars(config), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold[1/7]\n",
      "Epoch[0/50](50/254) || training loss 0.5263 || training accuracy 66.94% || training f1_score 0.6447 || lr 0.0001\n",
      "          training each f1 || mask f1 0.8882 || age f1 0.7744 || gender f1 0.889\n",
      "Epoch[0/50](100/254) || training loss 0.1595 || training accuracy 88.88% || training f1_score 0.8671 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9413 || age f1 0.8449 || gender f1 0.9322\n",
      "Epoch[0/50](150/254) || training loss 0.1216 || training accuracy 90.94% || training f1_score 0.8968 || lr 0.0001\n",
      "          training each f1 || mask f1 0.958 || age f1 0.875 || gender f1 0.9482\n",
      "Epoch[0/50](200/254) || training loss 0.09598 || training accuracy 93.28% || training f1_score 0.9267 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9662 || age f1 0.8956 || gender f1 0.956\n",
      "Epoch[0/50](250/254) || training loss 0.06479 || training accuracy 95.16% || training f1_score 0.9378 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9719 || age f1 0.91 || gender f1 0.962\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.7652! saving the best model..\n",
      "[Val] acc : 88.05%, loss: 0.2887, f1: 0.7652 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9857 || age f1 0.8171 || gender f1 0.976\n",
      "\n",
      "Epoch[1/50](50/254) || training loss 0.1259 || training accuracy 92.38% || training f1_score 0.9123 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9894 || age f1 0.9443 || gender f1 0.9834\n",
      "Epoch[1/50](100/254) || training loss 0.05025 || training accuracy 96.41% || training f1_score 0.9588 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9926 || age f1 0.9606 || gender f1 0.986\n",
      "Epoch[1/50](150/254) || training loss 0.04066 || training accuracy 96.72% || training f1_score 0.9598 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.994 || age f1 0.9675 || gender f1 0.9866\n",
      "Epoch[1/50](200/254) || training loss 0.02781 || training accuracy 98.00% || training f1_score 0.9779 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9949 || age f1 0.973 || gender f1 0.9879\n",
      "Epoch[1/50](250/254) || training loss 0.03221 || training accuracy 97.47% || training f1_score 0.9671 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9948 || age f1 0.9755 || gender f1 0.9887\n",
      "Calculating validation results...\n",
      "[Val] acc : 82.94%, loss: 0.517, f1: 0.7124 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9899 || age f1 0.7684 || gender f1 0.9684\n",
      "\n",
      "Epoch[2/50](50/254) || training loss 0.0577 || training accuracy 95.78% || training f1_score 0.945 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9938 || age f1 0.9791 || gender f1 0.9825\n",
      "Epoch[2/50](100/254) || training loss 0.0247 || training accuracy 98.34% || training f1_score 0.9796 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9958 || age f1 0.9851 || gender f1 0.988\n",
      "Epoch[2/50](150/254) || training loss 0.02331 || training accuracy 98.12% || training f1_score 0.9769 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9965 || age f1 0.9867 || gender f1 0.9895\n",
      "Epoch[2/50](200/254) || training loss 0.0203 || training accuracy 98.47% || training f1_score 0.9771 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9969 || age f1 0.9874 || gender f1 0.9911\n",
      "Epoch[2/50](250/254) || training loss 0.01566 || training accuracy 98.78% || training f1_score 0.9878 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9971 || age f1 0.9882 || gender f1 0.9924\n",
      "Calculating validation results...\n",
      "[Val] acc : 82.68%, loss: 0.6328, f1: 0.7208 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9848 || age f1 0.78 || gender f1 0.9653\n",
      "\n",
      "Epoch[3/50](50/254) || training loss 0.04439 || training accuracy 96.72% || training f1_score 0.9584 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9941 || age f1 0.9827 || gender f1 0.9873\n",
      "Epoch[3/50](100/254) || training loss 0.0268 || training accuracy 98.12% || training f1_score 0.9702 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9957 || age f1 0.9864 || gender f1 0.9896\n",
      "Epoch[3/50](150/254) || training loss 0.01595 || training accuracy 98.91% || training f1_score 0.9883 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.997 || age f1 0.9885 || gender f1 0.992\n",
      "Epoch[3/50](200/254) || training loss 0.01698 || training accuracy 98.97% || training f1_score 0.9904 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9974 || age f1 0.9899 || gender f1 0.9932\n",
      "Epoch[3/50](250/254) || training loss 0.01674 || training accuracy 98.62% || training f1_score 0.9826 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9973 || age f1 0.9902 || gender f1 0.9938\n",
      "Calculating validation results...\n",
      "[Val] acc : 82.53%, loss: 0.7366, f1: 0.6785 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9893 || age f1 0.7404 || gender f1 0.9755\n",
      "\n",
      "Epoch[4/50](50/254) || training loss 0.0449 || training accuracy 97.44% || training f1_score 0.9674 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9963 || age f1 0.9817 || gender f1 0.9944\n",
      "Epoch[4/50](100/254) || training loss 0.01594 || training accuracy 98.66% || training f1_score 0.9847 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.997 || age f1 0.9862 || gender f1 0.9959\n",
      "Epoch[4/50](150/254) || training loss 0.01392 || training accuracy 98.97% || training f1_score 0.9884 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9973 || age f1 0.9882 || gender f1 0.9969\n",
      "Epoch[4/50](200/254) || training loss 0.008381 || training accuracy 99.56% || training f1_score 0.9936 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9979 || age f1 0.9905 || gender f1 0.9972\n",
      "Epoch[4/50](250/254) || training loss 0.008522 || training accuracy 99.53% || training f1_score 0.9933 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9977 || age f1 0.9921 || gender f1 0.9975\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.60%, loss: 0.5353, f1: 0.7358 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9941 || age f1 0.7951 || gender f1 0.9799\n",
      "\n",
      "Epoch[5/50](50/254) || training loss 0.02428 || training accuracy 98.09% || training f1_score 0.9791 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9987 || age f1 0.9946 || gender f1 0.9864\n",
      "Epoch[5/50](100/254) || training loss 0.01067 || training accuracy 99.31% || training f1_score 0.9901 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9955 || gender f1 0.9915\n",
      "Epoch[5/50](150/254) || training loss 0.006144 || training accuracy 99.41% || training f1_score 0.9927 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9959 || gender f1 0.9936\n",
      "Epoch[5/50](200/254) || training loss 0.005699 || training accuracy 99.59% || training f1_score 0.9947 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9963 || gender f1 0.9948\n",
      "Epoch[5/50](250/254) || training loss 0.006746 || training accuracy 99.53% || training f1_score 0.9948 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9966 || gender f1 0.9955\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.42%, loss: 0.5616, f1: 0.6968 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9925 || age f1 0.7445 || gender f1 0.973\n",
      "\n",
      "Epoch[6/50](50/254) || training loss 0.0166 || training accuracy 99.22% || training f1_score 0.9922 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9989 || age f1 0.9948 || gender f1 0.998\n",
      "Epoch[6/50](100/254) || training loss 0.006625 || training accuracy 99.69% || training f1_score 0.996 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9987 || age f1 0.9965 || gender f1 0.9989\n",
      "Epoch[6/50](150/254) || training loss 0.003321 || training accuracy 99.81% || training f1_score 0.9977 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9988 || age f1 0.9973 || gender f1 0.9991\n",
      "Epoch[6/50](200/254) || training loss 0.005664 || training accuracy 99.56% || training f1_score 0.9965 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9974 || gender f1 0.9989\n",
      "Epoch[6/50](250/254) || training loss 0.004304 || training accuracy 99.72% || training f1_score 0.9971 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9976 || gender f1 0.999\n",
      "Calculating validation results...\n",
      "[Val] acc : 82.12%, loss: 0.7503, f1: 0.6719 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9915 || age f1 0.7381 || gender f1 0.9744\n",
      "\n",
      "Epoch[7/50](50/254) || training loss 0.0202 || training accuracy 98.59% || training f1_score 0.9746 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9974 || age f1 0.9934 || gender f1 0.9938\n",
      "Epoch[7/50](100/254) || training loss 0.0128 || training accuracy 98.81% || training f1_score 0.9843 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9975 || age f1 0.9942 || gender f1 0.994\n",
      "Epoch[7/50](150/254) || training loss 0.009624 || training accuracy 99.31% || training f1_score 0.9922 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9979 || age f1 0.9952 || gender f1 0.9949\n",
      "Epoch[7/50](200/254) || training loss 0.005059 || training accuracy 99.59% || training f1_score 0.9953 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9983 || age f1 0.996 || gender f1 0.9956\n",
      "Epoch[7/50](250/254) || training loss 0.00299 || training accuracy 99.75% || training f1_score 0.996 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9983 || age f1 0.9968 || gender f1 0.9962\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.34%, loss: 0.604, f1: 0.7429 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.993 || age f1 0.7742 || gender f1 0.9784\n",
      "\n",
      "Epoch[8/50](50/254) || training loss 0.003718 || training accuracy 99.72% || training f1_score 0.996 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9991 || age f1 0.9994 || gender f1 0.9983\n",
      "Epoch[8/50](100/254) || training loss 0.003115 || training accuracy 99.81% || training f1_score 0.9978 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9992 || age f1 0.9995 || gender f1 0.9984\n",
      "Epoch[8/50](150/254) || training loss 0.004973 || training accuracy 99.53% || training f1_score 0.9942 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9988 || age f1 0.9991 || gender f1 0.9983\n",
      "Epoch[8/50](200/254) || training loss 0.004545 || training accuracy 99.56% || training f1_score 0.9956 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9986 || age f1 0.9987 || gender f1 0.9984\n",
      "Epoch[8/50](250/254) || training loss 0.005566 || training accuracy 99.56% || training f1_score 0.9961 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9988 || age f1 0.9987 || gender f1 0.9982\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.94%, loss: 0.7426, f1: 0.7166 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9936 || age f1 0.7529 || gender f1 0.9795\n",
      "\n",
      "Epoch[9/50](50/254) || training loss 0.003889 || training accuracy 99.59% || training f1_score 0.9948 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9976 || age f1 0.9984 || gender f1 0.9987\n",
      "Epoch[9/50](100/254) || training loss 0.002503 || training accuracy 99.88% || training f1_score 0.9986 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9986 || age f1 0.9989 || gender f1 0.9992\n",
      "Epoch[9/50](150/254) || training loss 0.002872 || training accuracy 99.78% || training f1_score 0.9977 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9985 || age f1 0.9991 || gender f1 0.9993\n",
      "Epoch[9/50](200/254) || training loss 0.002276 || training accuracy 99.75% || training f1_score 0.9971 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9986 || age f1 0.9991 || gender f1 0.9993\n",
      "Epoch[9/50](250/254) || training loss 0.002983 || training accuracy 99.78% || training f1_score 0.9973 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9987 || age f1 0.9991 || gender f1 0.9992\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.16%, loss: 0.6412, f1: 0.6945 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9936 || age f1 0.7587 || gender f1 0.9796\n",
      "\n",
      "Epoch[10/50](50/254) || training loss 0.006771 || training accuracy 99.19% || training f1_score 0.9819 || lr 1.9687440434072263e-05\n",
      "          training each f1 || mask f1 0.9854 || age f1 0.9997 || gender f1 0.9997\n",
      "Epoch[10/50](100/254) || training loss 0.00192 || training accuracy 99.88% || training f1_score 0.9986 || lr 1.9687440434072263e-05\n",
      "          training each f1 || mask f1 0.9926 || age f1 0.9997 || gender f1 0.9995\n",
      "Epoch[10/50](150/254) || training loss 0.002464 || training accuracy 99.81% || training f1_score 0.9979 || lr 1.9687440434072263e-05\n",
      "          training each f1 || mask f1 0.995 || age f1 0.9994 || gender f1 0.9995\n",
      "Epoch[10/50](200/254) || training loss 0.0014 || training accuracy 99.97% || training f1_score 0.9992 || lr 1.9687440434072263e-05\n",
      "          training each f1 || mask f1 0.9963 || age f1 0.9995 || gender f1 0.9995\n",
      "Epoch[10/50](250/254) || training loss 0.001627 || training accuracy 99.78% || training f1_score 0.9966 || lr 1.9687440434072263e-05\n",
      "          training each f1 || mask f1 0.9967 || age f1 0.9996 || gender f1 0.9994\n",
      "Calculating validation results...\n",
      "[Val] acc : 86.71%, loss: 0.6267, f1: 0.6815 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.9875 || age f1 0.7524 || gender f1 0.9803\n",
      "\n",
      "Epoch[11/50](50/254) || training loss 0.002769 || training accuracy 99.88% || training f1_score 0.9985 || lr 1.673432436896142e-05\n",
      "          training each f1 || mask f1 0.9996 || age f1 0.9997 || gender f1 0.9993\n",
      "Epoch[11/50](100/254) || training loss 0.001722 || training accuracy 99.84% || training f1_score 0.9967 || lr 1.673432436896142e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9998 || gender f1 0.9994\n",
      "Epoch[11/50](150/254) || training loss 0.002008 || training accuracy 99.88% || training f1_score 0.9988 || lr 1.673432436896142e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9996 || gender f1 0.9995\n",
      "Epoch[11/50](200/254) || training loss 0.001453 || training accuracy 99.94% || training f1_score 0.9988 || lr 1.673432436896142e-05\n",
      "          training each f1 || mask f1 0.9994 || age f1 0.9996 || gender f1 0.9996\n",
      "Epoch[11/50](250/254) || training loss 0.0006008 || training accuracy 100.00% || training f1_score  1.0 || lr 1.673432436896142e-05\n",
      "          training each f1 || mask f1 0.9995 || age f1 0.9997 || gender f1 0.9997\n",
      "Calculating validation results...\n",
      "[Val] acc : 86.86%, loss: 0.6868, f1: 0.6907 || best acc : 88.05%, best loss: 0.2887, best f1: 0.7652\n",
      "[Val] each f1 || mask f1 0.993 || age f1 0.7657 || gender f1 0.9763\n",
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold[2/7]\n",
      "Epoch[0/50](50/254) || training loss 0.5106 || training accuracy 66.69% || training f1_score 0.636 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9107 || age f1 0.7675 || gender f1 0.862\n",
      "Epoch[0/50](100/254) || training loss 0.1827 || training accuracy 87.09% || training f1_score 0.8533 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9483 || age f1 0.835 || gender f1 0.9186\n",
      "Epoch[0/50](150/254) || training loss 0.1127 || training accuracy 92.00% || training f1_score 0.9129 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9624 || age f1 0.871 || gender f1 0.9386\n",
      "Epoch[0/50](200/254) || training loss 0.08661 || training accuracy 93.12% || training f1_score 0.916 || lr 0.0001\n",
      "          training each f1 || mask f1 0.9702 || age f1 0.8925 || gender f1 0.9486\n",
      "Epoch[0/50](250/254) || training loss 0.106 || training accuracy 93.06% || training f1_score 0.9091 || lr 0.0001\n",
      "          training each f1 || mask f1 0.974 || age f1 0.9041 || gender f1 0.9559\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.7556! saving the best model..\n",
      "[Val] acc : 75.50%, loss: 0.697, f1: 0.7556 || best acc : 75.50%, best loss: 0.697, best f1: 0.7556\n",
      "[Val] each f1 || mask f1 0.99 || age f1 0.781 || gender f1 0.9532\n",
      "\n",
      "Epoch[1/50](50/254) || training loss 0.09183 || training accuracy 93.59% || training f1_score 0.9237 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9886 || age f1 0.9538 || gender f1 0.9862\n",
      "Epoch[1/50](100/254) || training loss 0.05189 || training accuracy 96.12% || training f1_score 0.9623 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9913 || age f1 0.9656 || gender f1 0.9862\n",
      "Epoch[1/50](150/254) || training loss 0.03778 || training accuracy 97.19% || training f1_score 0.9663 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9932 || age f1 0.9714 || gender f1 0.9875\n",
      "Epoch[1/50](200/254) || training loss 0.03718 || training accuracy 97.84% || training f1_score 0.9721 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9935 || age f1 0.9755 || gender f1 0.9892\n",
      "Epoch[1/50](250/254) || training loss 0.02601 || training accuracy 98.12% || training f1_score 0.9764 || lr 8.5e-05\n",
      "          training each f1 || mask f1 0.9941 || age f1 0.9781 || gender f1 0.9902\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.8233! saving the best model..\n",
      "[Val] acc : 85.46%, loss: 0.6756, f1: 0.8233 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.99 || age f1 0.841 || gender f1 0.968\n",
      "\n",
      "Epoch[2/50](50/254) || training loss 0.05427 || training accuracy 96.88% || training f1_score 0.964 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.996 || age f1 0.9729 || gender f1 0.9968\n",
      "Epoch[2/50](100/254) || training loss 0.01782 || training accuracy 98.59% || training f1_score 0.9852 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9964 || age f1 0.9828 || gender f1 0.9961\n",
      "Epoch[2/50](150/254) || training loss 0.0186 || training accuracy 98.53% || training f1_score 0.9831 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9961 || age f1 0.9868 || gender f1 0.9951\n",
      "Epoch[2/50](200/254) || training loss 0.01217 || training accuracy 98.97% || training f1_score 0.9885 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9967 || age f1 0.9893 || gender f1 0.9946\n",
      "Epoch[2/50](250/254) || training loss 0.02117 || training accuracy 98.72% || training f1_score 0.986 || lr 7.225000000000001e-05\n",
      "          training each f1 || mask f1 0.9973 || age f1 0.9898 || gender f1 0.9949\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.90%, loss: 0.6399, f1: 0.765 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9953 || age f1 0.8078 || gender f1 0.9536\n",
      "\n",
      "Epoch[3/50](50/254) || training loss 0.02337 || training accuracy 98.44% || training f1_score 0.9808 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9941 || age f1 0.9922 || gender f1 0.9958\n",
      "Epoch[3/50](100/254) || training loss 0.01432 || training accuracy 98.97% || training f1_score 0.9871 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9952 || age f1 0.9943 || gender f1 0.9958\n",
      "Epoch[3/50](150/254) || training loss 0.009466 || training accuracy 99.22% || training f1_score 0.9896 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.996 || age f1 0.9949 || gender f1 0.9963\n",
      "Epoch[3/50](200/254) || training loss 0.01135 || training accuracy 99.19% || training f1_score 0.9896 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9964 || age f1 0.9949 || gender f1 0.9968\n",
      "Epoch[3/50](250/254) || training loss 0.008719 || training accuracy 99.38% || training f1_score 0.991 || lr 6.141250000000001e-05\n",
      "          training each f1 || mask f1 0.9967 || age f1 0.9953 || gender f1 0.9971\n",
      "Calculating validation results...\n",
      "[Val] acc : 88.01%, loss: 0.6189, f1: 0.7708 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9964 || age f1 0.8398 || gender f1 0.9628\n",
      "\n",
      "Epoch[4/50](50/254) || training loss 0.009017 || training accuracy 99.34% || training f1_score 0.9932 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.996 || gender f1 0.9977\n",
      "Epoch[4/50](100/254) || training loss 0.00692 || training accuracy 99.38% || training f1_score 0.9931 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9962 || gender f1 0.9979\n",
      "Epoch[4/50](150/254) || training loss 0.006326 || training accuracy 99.72% || training f1_score 0.9959 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9987 || age f1 0.9973 || gender f1 0.9982\n",
      "Epoch[4/50](200/254) || training loss 0.00564 || training accuracy 99.72% || training f1_score 0.995 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9976 || gender f1 0.9983\n",
      "Epoch[4/50](250/254) || training loss 0.009543 || training accuracy 99.25% || training f1_score 0.989 || lr 5.2200625000000005e-05\n",
      "          training each f1 || mask f1 0.9986 || age f1 0.9973 || gender f1 0.9983\n",
      "Calculating validation results...\n",
      "[Val] acc : 88.45%, loss: 0.5613, f1: 0.7918 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9953 || age f1 0.8416 || gender f1 0.9695\n",
      "\n",
      "Epoch[5/50](50/254) || training loss 0.008732 || training accuracy 99.41% || training f1_score 0.995 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1  1.0 || age f1 0.9962 || gender f1 0.9978\n",
      "Epoch[5/50](100/254) || training loss 0.008403 || training accuracy 99.50% || training f1_score 0.9921 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9985 || age f1 0.9978 || gender f1 0.9974\n",
      "Epoch[5/50](150/254) || training loss 0.00507 || training accuracy 99.53% || training f1_score 0.9948 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.9987 || age f1 0.9981 || gender f1 0.9973\n",
      "Epoch[5/50](200/254) || training loss 0.003294 || training accuracy 99.75% || training f1_score 0.9968 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9982 || gender f1 0.9978\n",
      "Epoch[5/50](250/254) || training loss 0.002746 || training accuracy 99.78% || training f1_score 0.9969 || lr 4.437053125e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.9985 || gender f1 0.9979\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.60%, loss: 0.7605, f1: 0.7762 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9958 || age f1 0.8133 || gender f1 0.9691\n",
      "\n",
      "Epoch[6/50](50/254) || training loss 0.004555 || training accuracy 99.69% || training f1_score 0.9967 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1  1.0 || age f1 0.9975 || gender f1 0.9994\n",
      "Epoch[6/50](100/254) || training loss 0.006291 || training accuracy 99.50% || training f1_score 0.9925 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9994 || age f1 0.9972 || gender f1 0.999\n",
      "Epoch[6/50](150/254) || training loss 0.00624 || training accuracy 99.62% || training f1_score 0.996 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9996 || age f1 0.9971 || gender f1 0.9991\n",
      "Epoch[6/50](200/254) || training loss 0.006553 || training accuracy 99.72% || training f1_score 0.9977 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9994 || age f1 0.9973 || gender f1 0.9993\n",
      "Epoch[6/50](250/254) || training loss 0.004521 || training accuracy 99.81% || training f1_score 0.9981 || lr 3.77149515625e-05\n",
      "          training each f1 || mask f1 0.9992 || age f1 0.9977 || gender f1 0.9994\n",
      "Calculating validation results...\n",
      "[Val] acc : 85.34%, loss: 0.8161, f1: 0.7589 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9927 || age f1 0.8007 || gender f1 0.9748\n",
      "\n",
      "Epoch[7/50](50/254) || training loss 0.00395 || training accuracy 99.75% || training f1_score 0.9977 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1  1.0 || age f1 0.9991 || gender f1 0.9984\n",
      "Epoch[7/50](100/254) || training loss 0.002927 || training accuracy 99.88% || training f1_score 0.9975 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9996 || age f1 0.9994 || gender f1 0.9989\n",
      "Epoch[7/50](150/254) || training loss 0.003055 || training accuracy 99.91% || training f1_score 0.9985 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9996 || gender f1 0.9992\n",
      "Epoch[7/50](200/254) || training loss 0.00254 || training accuracy 99.84% || training f1_score 0.9983 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.9996 || gender f1 0.9993\n",
      "Epoch[7/50](250/254) || training loss 0.002629 || training accuracy 99.69% || training f1_score 0.9955 || lr 3.2057708828124995e-05\n",
      "          training each f1 || mask f1 0.9989 || age f1 0.9996 || gender f1 0.9993\n",
      "Calculating validation results...\n",
      "[Val] acc : 88.34%, loss: 0.5844, f1: 0.7609 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9942 || age f1 0.8182 || gender f1 0.9678\n",
      "\n",
      "Epoch[8/50](50/254) || training loss 0.01697 || training accuracy 99.03% || training f1_score 0.9863 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9993 || age f1 0.992 || gender f1 0.9984\n",
      "Epoch[8/50](100/254) || training loss 0.0157 || training accuracy 99.25% || training f1_score 0.99 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9985 || age f1 0.9934 || gender f1 0.9986\n",
      "Epoch[8/50](150/254) || training loss 0.006854 || training accuracy 99.72% || training f1_score 0.996 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9988 || age f1 0.9953 || gender f1 0.9985\n",
      "Epoch[8/50](200/254) || training loss 0.003735 || training accuracy 99.72% || training f1_score 0.9968 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.999 || age f1 0.996 || gender f1 0.9987\n",
      "Epoch[8/50](250/254) || training loss 0.002995 || training accuracy 99.81% || training f1_score 0.998 || lr 2.7249052503906245e-05\n",
      "          training each f1 || mask f1 0.9992 || age f1 0.9966 || gender f1 0.9988\n",
      "Calculating validation results...\n",
      "[Val] acc : 86.12%, loss: 0.6167, f1: 0.7405 || best acc : 85.46%, best loss: 0.6756, best f1: 0.8233\n",
      "[Val] each f1 || mask f1 0.9932 || age f1 0.8069 || gender f1 0.9687\n",
      "\n",
      "Epoch[9/50](50/254) || training loss 0.01039 || training accuracy 99.38% || training f1_score 0.9945 || lr 2.3161694628320308e-05\n",
      "          training each f1 || mask f1 0.9988 || age f1 0.9953 || gender f1 0.999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d91e83aab147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mlabel_list\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmulti_class_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k-fold setting\n",
    "skf = StratifiedKFold(n_splits=config.n_splits)\n",
    "csv_path = os.path.join(config.data_dir,'train.csv')\n",
    "data = pd.read_csv(csv_path)\n",
    "labels = [ AgeLabels.from_number(d) for d in list(data.age.values)]\n",
    "data_list = list(data.values)\n",
    "# for i, (train_idx, valid_idx) in enumerate(skf.split(data_list, labels)):\n",
    "#     print(i)\n",
    "#     print(len(train_idx), len(valid_idx))\n",
    "#     print(data.loc[valid_idx])\n",
    "\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(data_list, labels)):\n",
    "    counter = 0\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = 0\n",
    "    train_loader, val_loader = getDataloader(train_idx, valid_idx)\n",
    "    model = ResnextMultiheadModel().to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    criterion = FocalLoss()\n",
    "#     criterion_mask = F1Loss(classes=3)\n",
    "#     criterion_age = F1Loss(classes=3)\n",
    "#     criterion_gender = F1Loss(classes=2)\n",
    "    optimizer = Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=config.lr,\n",
    "        weight_decay=5e-4\n",
    "    )\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.85)\n",
    "#     scheduler = StepLR(optimizer, config.lr_decay_step, gamma=0.5)\n",
    "    print(f\"kfold[{i+1}/{config.n_splits}]\")\n",
    "    for epoch in range(config.epochs):\n",
    "        # train loop\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        label_list=[]\n",
    "        pred_list=[]\n",
    "        mask_label_list=[]\n",
    "        mask_pred_list=[]\n",
    "        age_label_list=[]\n",
    "        age_pred_list=[]\n",
    "        gender_label_list=[]\n",
    "        gender_pred_list=[]\n",
    "        for idx, train_batch in enumerate(train_loader):\n",
    "            inputs, (mask_labels, gender_labels, age_labels, multi_class_labels) = train_batch\n",
    "            inputs = inputs.to(device)\n",
    "            mask_labels = mask_labels.to(device)\n",
    "            gender_labels = gender_labels.to(device)\n",
    "            age_labels = age_labels.to(device)\n",
    "            multi_class_labels = multi_class_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            mask_outs, age_outs, gender_outs = model(inputs)\n",
    "            mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "            age_preds = torch.argmax(age_outs, dim=-1)\n",
    "            gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "\n",
    "            multi_preds = mask_preds * 6 + gender_preds * 3 + age_preds\n",
    "            \n",
    "            \n",
    "            mask_loss = criterion(mask_outs, mask_labels)\n",
    "            age_loss = criterion(age_outs, age_labels)\n",
    "            gender_loss = criterion(gender_outs, gender_labels)\n",
    "#             mask_loss = criterion_mask(mask_outs, mask_labels)\n",
    "#             age_loss = criterion_age(age_outs, age_labels)\n",
    "#             gender_loss = criterion_gender(gender_outs, gender_labels)\n",
    "\n",
    "            loss = mask_loss + gender_loss + 2*age_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            label_list+=multi_class_labels.detach().cpu()\n",
    "            pred_list+=multi_preds.detach().cpu()\n",
    "\n",
    "            mask_label_list+=mask_labels.detach().cpu()\n",
    "            mask_pred_list+=mask_preds.detach().cpu()\n",
    "            age_label_list+=age_labels.detach().cpu()\n",
    "            age_pred_list+=age_preds.detach().cpu()\n",
    "            gender_label_list+=gender_labels.detach().cpu()\n",
    "            gender_pred_list+=gender_preds.detach().cpu()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "            matches += (multi_preds == multi_class_labels).sum().item()\n",
    "            if (idx + 1) % config.log_interval == 0:\n",
    "                train_loss = loss_value / config.log_interval\n",
    "                train_acc = matches / config.batch_size / config.log_interval\n",
    "                train_f1 = f1_score(label_list, pred_list, average='macro')\n",
    "                mask_f1 = f1_score(mask_label_list, mask_pred_list, average='macro')\n",
    "                age_f1 = f1_score(age_label_list, age_pred_list, average='macro')\n",
    "                gender_f1 = f1_score(gender_label_list, gender_pred_list, average='macro')\n",
    "                current_lr = get_lr(optimizer)\n",
    "                print(\n",
    "                    f\"Epoch[{epoch}/{config.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || training f1_score {train_f1:4.4} || lr {current_lr}\"\n",
    "                )\n",
    "                print(f\"          training each f1 || mask f1 {mask_f1:4.4} || age f1 {age_f1:4.4} || gender f1 {gender_f1:4.4}\")\n",
    "    #             logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "    #             logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "    #             logger.add_scalar(\"Train/f1_score\", train_f1, epoch * len(train_loader) + idx)\n",
    "\n",
    "                loss_value = 0\n",
    "                matches = 0\n",
    "                label_list=[]\n",
    "                pred_list=[]\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # val loop\n",
    "        with torch.no_grad():\n",
    "            print(\"Calculating validation results...\")\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items = []\n",
    "            label_list=[]\n",
    "            pred_list=[]\n",
    "            mask_label_list=[]\n",
    "            mask_pred_list=[]\n",
    "            age_label_list=[]\n",
    "            age_pred_list=[]\n",
    "            gender_label_list=[]\n",
    "            gender_pred_list=[]\n",
    "            data_len = 0\n",
    "            for val_batch in val_loader:\n",
    "                inputs, (mask_labels, gender_labels, age_labels, multi_class_labels) = val_batch\n",
    "                data_len += len(multi_class_labels)\n",
    "                inputs = inputs.to(device)\n",
    "                mask_labels = mask_labels.to(device)\n",
    "                gender_labels = gender_labels.to(device)\n",
    "                age_labels = age_labels.to(device)\n",
    "                multi_class_labels = multi_class_labels.to(device)\n",
    "\n",
    "                mask_outs, age_outs, gender_outs = model(inputs)\n",
    "                mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "                age_preds = torch.argmax(age_outs, dim=-1)\n",
    "                gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "                multi_preds = mask_preds * 6 + gender_preds * 3 + age_preds\n",
    "\n",
    "                label_list+=multi_class_labels.detach().cpu()\n",
    "                pred_list+=multi_preds.detach().cpu()\n",
    "                mask_label_list+=mask_labels.detach().cpu()\n",
    "                mask_pred_list+=mask_preds.detach().cpu()\n",
    "                age_label_list+=age_labels.detach().cpu()\n",
    "                age_pred_list+=age_preds.detach().cpu()\n",
    "                gender_label_list+=gender_labels.detach().cpu()\n",
    "                gender_pred_list+=gender_preds.detach().cpu()\n",
    "                \n",
    "                mask_loss = criterion(mask_outs, mask_labels)\n",
    "                age_loss = criterion(age_outs, age_labels)\n",
    "                gender_loss = criterion(gender_outs, gender_labels)\n",
    "#                 mask_loss = criterion_mask(mask_outs, mask_labels)\n",
    "#                 age_loss = criterion_age(age_outs, age_labels)\n",
    "#                 gender_loss = criterion_gender(gender_outs, gender_labels)\n",
    "                loss = mask_loss + 2*age_loss + gender_loss\n",
    "\n",
    "                acc_item = (multi_class_labels == multi_preds).sum().item()\n",
    "                val_loss_items.append(loss.item())\n",
    "                val_acc_items.append(acc_item)\n",
    "\n",
    "            val_loss = float(np.sum(val_loss_items) / len(val_loader))\n",
    "            val_acc = float(np.sum(val_acc_items) / data_len)\n",
    "            val_f1= float(f1_score(label_list,pred_list,average=\"macro\"))\n",
    "            val_mask_f1 = f1_score(mask_label_list, mask_pred_list, average='macro')\n",
    "            val_age_f1 = f1_score(age_label_list, age_pred_list, average='macro')\n",
    "            val_gender_f1 = f1_score(gender_label_list, gender_pred_list, average='macro')\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                print(f\"New best model for val f1 : {val_f1:4.4}! saving the best model..\")\n",
    "                torch.save(model.module.state_dict(), f\"{save_dir}/best_{i}.pth\")\n",
    "                best_val_f1 = val_f1\n",
    "                best_val_acc = val_acc\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "            torch.save(model.module.state_dict(), f\"{save_dir}/last_{i}.pth\")\n",
    "            print(\n",
    "                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.4}, f1: {val_f1:4.4} || \"\n",
    "                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.4}, best f1: {best_val_f1:4.4}\"\n",
    "            )\n",
    "            print(f\"[Val] each f1 || mask f1 {val_mask_f1:4.4} || age f1 {val_age_f1:4.4} || gender f1 {val_gender_f1:4.4}\")\n",
    "            if counter > config.patience:\n",
    "                print(\"Early Stopping!\")\n",
    "                counter = 0\n",
    "                break\n",
    "#             logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "#             logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "#             logger.add_scalar(\"Val/f1\", val_f1, epoch)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
