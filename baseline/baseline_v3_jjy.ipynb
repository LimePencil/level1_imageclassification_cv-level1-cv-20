{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, Subset, random_split, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config():\n",
    "    seed = 42\n",
    "    \n",
    "    # 데이터\n",
    "    data_dir = './input/data/train' #\n",
    "    resize = [224, 224]\n",
    "    val_ratio = 0.2\n",
    "    \n",
    "    # 학습 설정\n",
    "    epochs = 50 \n",
    "    batch_size = 64\n",
    "    valid_batch_size = 1000\n",
    "    lr = 1e-4\n",
    "    lr_decay_step = 10\n",
    "    log_interval = 50\n",
    "    \n",
    "    # 세이브 경로\n",
    "    save_dir = './exp'\n",
    "    \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 함수\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base setting\n",
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define transform (Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=(0.548, 0.504, 0.479)\n",
    "std=(0.237, 0.247, 0.246)\n",
    "train_transform = Compose([\n",
    "    CenterCrop(height=480, width=320),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0, interpolation=cv2.INTER_LINEAR),\n",
    "    HorizontalFlip(p=0.5),\n",
    "#     ShiftScaleRotate(p=0.5),\n",
    "#     HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "    GaussNoise(p=0.5),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)\n",
    "val_transform = Compose([\n",
    "    CenterCrop(height=480, width=320),\n",
    "    Resize(config.resize[0], config.resize[1], p=1.0),\n",
    "    Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base dataset class\n",
    "class BaseDataset(Dataset):\n",
    "    num_classes = 3*2*3\n",
    "    \n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, val_ratio=0.2, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.indices = defaultdict(list)\n",
    "        \n",
    "        self.val_ratio = val_ratio\n",
    "        \n",
    "        \n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        profiles = [profile for profile in profiles if not profile.startswith(\".\")]\n",
    "        split_profiles = self._split_profile(profiles, self.val_ratio)\n",
    "\n",
    "        cnt = 0\n",
    "        for phase, indices in split_profiles.items():\n",
    "            for _idx in indices:\n",
    "                profile = profiles[_idx]\n",
    "                img_folder = os.path.join(self.img_dir, profile)\n",
    "                for file_name in os.listdir(img_folder):\n",
    "                    _file_name, ext = os.path.splitext(file_name)\n",
    "                    if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                    mask_label = self._file_names[_file_name]\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = GenderLabels.from_str(gender)\n",
    "                    age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(mask_label)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "                    self.indices[phase].append(cnt)\n",
    "                    cnt += 1\n",
    "                    \n",
    "    def split_dataset(self) -> List[Subset]:\n",
    "        return [Subset(self, indices) for phase, indices in self.indices.items()]\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    \n",
    "    # 이외 utils\n",
    "    @staticmethod\n",
    "    def _split_profile(profiles, val_ratio):\n",
    "        length = len(profiles)\n",
    "        n_val = int(length * val_ratio)\n",
    "\n",
    "        val_indices = set(random.choices(range(length), k=n_val))\n",
    "        train_indices = set(range(length)) - val_indices\n",
    "        return {\n",
    "            \"train\": train_indices,\n",
    "            \"val\": val_indices\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "    \n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset(img_dir = f'{config.data_dir}/images', val_ratio = config.val_ratio)\n",
    "\n",
    "train_dataset, val_dataset = dataset.split_dataset()\n",
    "\n",
    "train_dataset.dataset.set_transform(train_transform)\n",
    "val_dataset.dataset.set_transform(val_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.valid_batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 24,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaseModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.base_model = models.vit_b_16(pretrained=True)\n",
    "#         self.base_model.heads.head = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnextModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=1000, out_features=num_classes, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "num_classes = train_dataset.dataset.num_classes\n",
    "print(num_classes)\n",
    "# model = BaseModel(num_classes=num_classes).to(device)\n",
    "model = ResnextModel(num_classes=num_classes).to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss , metric , optimizer , scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = FocalLoss()\n",
    "optimizer = Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=config.lr,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "scheduler = StepLR(optimizer, config.lr_decay_step, gamma=0.5)\n",
    "# -- scheduler: ReduceLROnPlateau\n",
    "# 성능이 향상되지 않을 때 learning rate를 줄입니다. patience=10은 10회 동안 성능 향상이 없을 경우입니다.\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "# -- scheduler: CosineAnnealingLR\n",
    "# CosineAnnealing은 learning rate를 cosine 그래프처럼 변화시킵니다.\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path : exp5\n"
     ]
    }
   ],
   "source": [
    "# 세이브 경로\n",
    "path = Path(config.save_dir)\n",
    "if (not path.exists()):\n",
    "    save_dir = str(path)\n",
    "else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    save_dir = f\"{path}{n}\"\n",
    "\n",
    "print(\"save path : \" + save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(log_dir=save_dir)\n",
    "with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(vars(config), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50](50/242) || training loss 0.9937 || training accuracy 62.75% || training f1_score 0.36 || lr 0.0001\n",
      "Epoch[0/50](100/242) || training loss 0.2306 || training accuracy 86.91% || training f1_score 0.718 || lr 0.0001\n",
      "Epoch[0/50](150/242) || training loss 0.1501 || training accuracy 89.84% || training f1_score 0.7623 || lr 0.0001\n",
      "Epoch[0/50](200/242) || training loss 0.1232 || training accuracy 90.56% || training f1_score 0.7919 || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val loss : 15.77%! saving the best model..\n",
      "[Val] acc : 89.02%, loss: 0.16, f1: 0.0009372 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[1/50](50/242) || training loss 0.0499 || training accuracy 95.75% || training f1_score 0.8801 || lr 0.0001\n",
      "Epoch[1/50](100/242) || training loss 0.04179 || training accuracy 96.44% || training f1_score 0.9146 || lr 0.0001\n",
      "Epoch[1/50](150/242) || training loss 0.03622 || training accuracy 97.25% || training f1_score 0.9231 || lr 0.0001\n",
      "Epoch[1/50](200/242) || training loss 0.04308 || training accuracy 96.72% || training f1_score 0.9209 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.52%, loss:  0.2, f1: 0.0008753 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[2/50](50/242) || training loss 0.02441 || training accuracy 98.06% || training f1_score 0.9537 || lr 0.0001\n",
      "Epoch[2/50](100/242) || training loss 0.01676 || training accuracy 98.81% || training f1_score 0.9715 || lr 0.0001\n",
      "Epoch[2/50](150/242) || training loss 0.01154 || training accuracy 99.22% || training f1_score 0.9811 || lr 0.0001\n",
      "Epoch[2/50](200/242) || training loss 0.01499 || training accuracy 98.91% || training f1_score 0.9748 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.05%, loss: 0.22, f1: 0.0009172 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[3/50](50/242) || training loss 0.01825 || training accuracy 98.59% || training f1_score 0.9636 || lr 0.0001\n",
      "Epoch[3/50](100/242) || training loss 0.01868 || training accuracy 98.56% || training f1_score 0.9537 || lr 0.0001\n",
      "Epoch[3/50](150/242) || training loss 0.01402 || training accuracy 98.84% || training f1_score 0.9743 || lr 0.0001\n",
      "Epoch[3/50](200/242) || training loss 0.01204 || training accuracy 98.75% || training f1_score 0.9684 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.78%, loss: 0.23, f1: 0.000863 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[4/50](50/242) || training loss 0.01238 || training accuracy 99.09% || training f1_score 0.9782 || lr 0.0001\n",
      "Epoch[4/50](100/242) || training loss 0.01892 || training accuracy 98.62% || training f1_score 0.9681 || lr 0.0001\n",
      "Epoch[4/50](150/242) || training loss 0.01827 || training accuracy 98.50% || training f1_score 0.96 || lr 0.0001\n",
      "Epoch[4/50](200/242) || training loss 0.01888 || training accuracy 98.28% || training f1_score 0.9565 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.75%, loss: 0.28, f1: 0.0008765 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[5/50](50/242) || training loss 0.01687 || training accuracy 98.28% || training f1_score 0.9681 || lr 0.0001\n",
      "Epoch[5/50](100/242) || training loss 0.01181 || training accuracy 98.81% || training f1_score 0.9729 || lr 0.0001\n",
      "Epoch[5/50](150/242) || training loss 0.01525 || training accuracy 98.72% || training f1_score 0.9758 || lr 0.0001\n",
      "Epoch[5/50](200/242) || training loss 0.01367 || training accuracy 98.91% || training f1_score 0.9755 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 88.23%, loss: 0.27, f1: 0.0008927 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[6/50](50/242) || training loss 0.03127 || training accuracy 97.59% || training f1_score 0.9495 || lr 0.0001\n",
      "Epoch[6/50](100/242) || training loss 0.02401 || training accuracy 97.91% || training f1_score 0.9393 || lr 0.0001\n",
      "Epoch[6/50](150/242) || training loss 0.01968 || training accuracy 98.72% || training f1_score 0.9675 || lr 0.0001\n",
      "Epoch[6/50](200/242) || training loss 0.01104 || training accuracy 99.06% || training f1_score 0.9736 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.82%, loss: 0.28, f1: 0.0008361 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[7/50](50/242) || training loss 0.01279 || training accuracy 98.94% || training f1_score 0.974 || lr 0.0001\n",
      "Epoch[7/50](100/242) || training loss 0.006438 || training accuracy 99.47% || training f1_score 0.9812 || lr 0.0001\n",
      "Epoch[7/50](150/242) || training loss 0.01351 || training accuracy 98.84% || training f1_score 0.9718 || lr 0.0001\n",
      "Epoch[7/50](200/242) || training loss 0.01264 || training accuracy 99.16% || training f1_score 0.9803 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.09%, loss: 0.21, f1: 0.0009162 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[8/50](50/242) || training loss 0.01164 || training accuracy 98.94% || training f1_score 0.9754 || lr 0.0001\n",
      "Epoch[8/50](100/242) || training loss 0.02126 || training accuracy 98.44% || training f1_score 0.959 || lr 0.0001\n",
      "Epoch[8/50](150/242) || training loss 0.01021 || training accuracy 99.09% || training f1_score 0.9762 || lr 0.0001\n",
      "Epoch[8/50](200/242) || training loss 0.01739 || training accuracy 98.72% || training f1_score 0.9664 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.11%, loss: 0.22, f1: 0.0008747 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[9/50](50/242) || training loss 0.01891 || training accuracy 98.50% || training f1_score 0.9629 || lr 0.0001\n",
      "Epoch[9/50](100/242) || training loss 0.01637 || training accuracy 98.72% || training f1_score 0.9808 || lr 0.0001\n",
      "Epoch[9/50](150/242) || training loss 0.007635 || training accuracy 99.41% || training f1_score 0.9796 || lr 0.0001\n",
      "Epoch[9/50](200/242) || training loss 0.004274 || training accuracy 99.56% || training f1_score 0.9875 || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.16%, loss: 0.21, f1: 0.0009294 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[10/50](50/242) || training loss 0.00184 || training accuracy 99.88% || training f1_score 0.9954 || lr 5e-05\n",
      "Epoch[10/50](100/242) || training loss 0.003519 || training accuracy 99.78% || training f1_score 0.996 || lr 5e-05\n",
      "Epoch[10/50](150/242) || training loss 0.001392 || training accuracy 99.81% || training f1_score 0.9953 || lr 5e-05\n",
      "Epoch[10/50](200/242) || training loss 0.002229 || training accuracy 99.81% || training f1_score 0.9888 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.25%, loss: 0.19, f1: 0.0009352 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[11/50](50/242) || training loss 0.000616 || training accuracy 100.00% || training f1_score  1.0 || lr 5e-05\n",
      "Epoch[11/50](100/242) || training loss 0.001448 || training accuracy 99.84% || training f1_score 0.9931 || lr 5e-05\n",
      "Epoch[11/50](150/242) || training loss 0.00135 || training accuracy 99.88% || training f1_score 0.9947 || lr 5e-05\n",
      "Epoch[11/50](200/242) || training loss 0.0008615 || training accuracy 99.91% || training f1_score 0.9959 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.43%, loss:  0.2, f1: 0.0009345 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[12/50](50/242) || training loss 0.0006918 || training accuracy 99.97% || training f1_score 0.9997 || lr 5e-05\n",
      "Epoch[12/50](100/242) || training loss 0.002108 || training accuracy 99.88% || training f1_score 0.997 || lr 5e-05\n",
      "Epoch[12/50](150/242) || training loss 0.0007495 || training accuracy 99.94% || training f1_score 0.9978 || lr 5e-05\n",
      "Epoch[12/50](200/242) || training loss 0.0006704 || training accuracy 99.97% || training f1_score 0.9998 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.34%, loss:  0.2, f1: 0.000918 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[13/50](50/242) || training loss 0.001037 || training accuracy 99.97% || training f1_score 0.9994 || lr 5e-05\n",
      "Epoch[13/50](100/242) || training loss 0.0007489 || training accuracy 99.97% || training f1_score 0.9985 || lr 5e-05\n",
      "Epoch[13/50](150/242) || training loss 0.0007074 || training accuracy 99.97% || training f1_score 0.9999 || lr 5e-05\n",
      "Epoch[13/50](200/242) || training loss 0.0006267 || training accuracy 99.94% || training f1_score 0.9998 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.60%, loss: 0.19, f1: 0.0009497 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[14/50](50/242) || training loss 0.0003749 || training accuracy 100.00% || training f1_score  1.0 || lr 5e-05\n",
      "Epoch[14/50](100/242) || training loss 0.0003973 || training accuracy 100.00% || training f1_score  1.0 || lr 5e-05\n",
      "Epoch[14/50](150/242) || training loss 0.0002897 || training accuracy 100.00% || training f1_score  1.0 || lr 5e-05\n",
      "Epoch[14/50](200/242) || training loss 0.000668 || training accuracy 99.94% || training f1_score 0.998 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.84%, loss:  0.2, f1: 0.0009437 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[15/50](50/242) || training loss 0.0004547 || training accuracy 100.00% || training f1_score  1.0 || lr 5e-05\n",
      "Epoch[15/50](100/242) || training loss 0.001185 || training accuracy 99.88% || training f1_score 0.9992 || lr 5e-05\n",
      "Epoch[15/50](150/242) || training loss 0.001309 || training accuracy 99.91% || training f1_score 0.9978 || lr 5e-05\n",
      "Epoch[15/50](200/242) || training loss 0.002553 || training accuracy 99.75% || training f1_score 0.9927 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.16%, loss: 0.19, f1: 0.0009532 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[16/50](50/242) || training loss 0.01162 || training accuracy 99.16% || training f1_score 0.9785 || lr 5e-05\n",
      "Epoch[16/50](100/242) || training loss 0.003973 || training accuracy 99.75% || training f1_score 0.9897 || lr 5e-05\n",
      "Epoch[16/50](150/242) || training loss 0.0104 || training accuracy 99.28% || training f1_score 0.9821 || lr 5e-05\n",
      "Epoch[16/50](200/242) || training loss 0.01737 || training accuracy 98.72% || training f1_score 0.9781 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.40%, loss: 0.23, f1: 0.0009218 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[17/50](50/242) || training loss 0.007383 || training accuracy 99.28% || training f1_score 0.9903 || lr 5e-05\n",
      "Epoch[17/50](100/242) || training loss 0.007984 || training accuracy 99.47% || training f1_score 0.9936 || lr 5e-05\n",
      "Epoch[17/50](150/242) || training loss 0.00626 || training accuracy 99.34% || training f1_score 0.9875 || lr 5e-05\n",
      "Epoch[17/50](200/242) || training loss 0.01045 || training accuracy 99.34% || training f1_score 0.9887 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.05%, loss: 0.23, f1: 0.0009682 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[18/50](50/242) || training loss 0.009742 || training accuracy 99.06% || training f1_score 0.9789 || lr 5e-05\n",
      "Epoch[18/50](100/242) || training loss 0.01196 || training accuracy 99.12% || training f1_score 0.981 || lr 5e-05\n",
      "Epoch[18/50](150/242) || training loss 0.01436 || training accuracy 99.28% || training f1_score 0.9829 || lr 5e-05\n",
      "Epoch[18/50](200/242) || training loss 0.00892 || training accuracy 99.50% || training f1_score 0.9888 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.90%, loss: 0.23, f1: 0.0008702 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[19/50](50/242) || training loss 0.009662 || training accuracy 99.38% || training f1_score 0.9747 || lr 5e-05\n",
      "Epoch[19/50](100/242) || training loss 0.004561 || training accuracy 99.59% || training f1_score 0.9945 || lr 5e-05\n",
      "Epoch[19/50](150/242) || training loss 0.00335 || training accuracy 99.59% || training f1_score 0.9944 || lr 5e-05\n",
      "Epoch[19/50](200/242) || training loss 0.004966 || training accuracy 99.69% || training f1_score 0.9939 || lr 5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.07%, loss: 0.19, f1: 0.0009147 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[20/50](50/242) || training loss 0.001534 || training accuracy 99.91% || training f1_score 0.9982 || lr 2.5e-05\n",
      "Epoch[20/50](100/242) || training loss 0.002779 || training accuracy 99.91% || training f1_score 0.9964 || lr 2.5e-05\n",
      "Epoch[20/50](150/242) || training loss 0.0005224 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[20/50](200/242) || training loss 0.0007189 || training accuracy 99.97% || training f1_score 0.9999 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.51%, loss: 0.19, f1: 0.0009256 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[21/50](50/242) || training loss 0.000401 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[21/50](100/242) || training loss 0.0004779 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[21/50](150/242) || training loss 0.0005305 || training accuracy 99.97% || training f1_score 0.9994 || lr 2.5e-05\n",
      "Epoch[21/50](200/242) || training loss 0.0005363 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.04%, loss:  0.2, f1: 0.0008952 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[22/50](50/242) || training loss 0.0004727 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[22/50](100/242) || training loss 0.001273 || training accuracy 99.88% || training f1_score 0.997 || lr 2.5e-05\n",
      "Epoch[22/50](150/242) || training loss 0.0004753 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[22/50](200/242) || training loss 0.000365 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.66%, loss: 0.18, f1: 0.0009172 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[23/50](50/242) || training loss 0.0002919 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[23/50](100/242) || training loss 0.0006995 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[23/50](150/242) || training loss 0.0003218 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[23/50](200/242) || training loss 0.0002996 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.95%, loss: 0.17, f1: 0.0009487 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[24/50](50/242) || training loss 0.0003455 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[24/50](100/242) || training loss 0.0004716 || training accuracy 99.97% || training f1_score 0.9999 || lr 2.5e-05\n",
      "Epoch[24/50](150/242) || training loss 0.0003923 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[24/50](200/242) || training loss 0.0005555 || training accuracy 99.97% || training f1_score 0.9994 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.92%, loss: 0.17, f1: 0.0009521 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[25/50](50/242) || training loss 0.0006187 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[25/50](100/242) || training loss 0.0003894 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[25/50](150/242) || training loss 0.0004263 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[25/50](200/242) || training loss 0.002841 || training accuracy 99.88% || training f1_score 0.9975 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.39%, loss: 0.18, f1: 0.0009768 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[26/50](50/242) || training loss 0.001111 || training accuracy 99.97% || training f1_score 0.9994 || lr 2.5e-05\n",
      "Epoch[26/50](100/242) || training loss 0.002446 || training accuracy 99.97% || training f1_score 0.9998 || lr 2.5e-05\n",
      "Epoch[26/50](150/242) || training loss 0.000818 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[26/50](200/242) || training loss 0.0007364 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.60%, loss: 0.18, f1: 0.0009456 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[27/50](50/242) || training loss 0.0005255 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[27/50](100/242) || training loss 0.0004658 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[27/50](150/242) || training loss 0.0005531 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[27/50](200/242) || training loss 0.0005044 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.01%, loss: 0.17, f1: 0.000933 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[28/50](50/242) || training loss 0.0003592 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[28/50](100/242) || training loss 0.0004977 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[28/50](150/242) || training loss 0.0003401 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[28/50](200/242) || training loss 0.0005728 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.83%, loss: 0.17, f1: 0.0009427 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[29/50](50/242) || training loss 0.0004001 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[29/50](100/242) || training loss 0.0004764 || training accuracy 100.00% || training f1_score  1.0 || lr 2.5e-05\n",
      "Epoch[29/50](150/242) || training loss 0.0008463 || training accuracy 99.91% || training f1_score 0.9988 || lr 2.5e-05\n",
      "Epoch[29/50](200/242) || training loss 0.002756 || training accuracy 99.88% || training f1_score 0.9963 || lr 2.5e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.01%, loss: 0.19, f1: 0.0009135 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[30/50](50/242) || training loss 0.002775 || training accuracy 99.81% || training f1_score 0.999 || lr 1.25e-05\n",
      "Epoch[30/50](100/242) || training loss 0.003334 || training accuracy 99.81% || training f1_score 0.9985 || lr 1.25e-05\n",
      "Epoch[30/50](150/242) || training loss 0.001927 || training accuracy 99.91% || training f1_score 0.9993 || lr 1.25e-05\n",
      "Epoch[30/50](200/242) || training loss 0.001245 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.54%, loss:  0.2, f1: 0.0009576 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[31/50](50/242) || training loss 0.0005922 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[31/50](100/242) || training loss 0.0005433 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[31/50](150/242) || training loss 0.0007334 || training accuracy 99.97% || training f1_score 0.9998 || lr 1.25e-05\n",
      "Epoch[31/50](200/242) || training loss 0.001008 || training accuracy 99.88% || training f1_score 0.9978 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.72%, loss: 0.19, f1: 0.0009374 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[32/50](50/242) || training loss 0.001517 || training accuracy 99.91% || training f1_score 0.9996 || lr 1.25e-05\n",
      "Epoch[32/50](100/242) || training loss 0.0005691 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[32/50](150/242) || training loss 0.0005444 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[32/50](200/242) || training loss 0.0004367 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.21%, loss: 0.17, f1: 0.000953 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[33/50](50/242) || training loss 0.0004864 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[33/50](100/242) || training loss 0.0003691 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[33/50](150/242) || training loss 0.0004219 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[33/50](200/242) || training loss 0.0005654 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.56%, loss: 0.17, f1: 0.0009553 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[34/50](50/242) || training loss 0.0004605 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[34/50](100/242) || training loss 0.0006621 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[34/50](150/242) || training loss 0.0003534 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[34/50](200/242) || training loss 0.0005184 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.27%, loss: 0.19, f1: 0.0009465 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[35/50](50/242) || training loss 0.0003244 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[35/50](100/242) || training loss 0.0003275 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[35/50](150/242) || training loss 0.0004236 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[35/50](200/242) || training loss 0.0003643 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.98%, loss: 0.18, f1: 0.0009477 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[36/50](50/242) || training loss 0.0005134 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[36/50](100/242) || training loss 0.0004901 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[36/50](150/242) || training loss 0.0004233 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[36/50](200/242) || training loss 0.0006363 || training accuracy 99.97% || training f1_score 0.9983 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.92%, loss: 0.19, f1: 0.0009132 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[37/50](50/242) || training loss 0.0004108 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[37/50](100/242) || training loss 0.0009983 || training accuracy 99.94% || training f1_score 0.9961 || lr 1.25e-05\n",
      "Epoch[37/50](150/242) || training loss 0.0005314 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[37/50](200/242) || training loss 0.001785 || training accuracy 99.94% || training f1_score 0.9962 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.63%, loss: 0.19, f1: 0.0009358 || best acc : 89.02%, best loss: 0.16, best f1: 0.0009372\n",
      "\n",
      "Epoch[38/50](50/242) || training loss 0.003514 || training accuracy 99.78% || training f1_score 0.9912 || lr 1.25e-05\n",
      "Epoch[38/50](100/242) || training loss 0.006263 || training accuracy 99.62% || training f1_score 0.986 || lr 1.25e-05\n",
      "Epoch[38/50](150/242) || training loss 0.003494 || training accuracy 99.78% || training f1_score 0.9914 || lr 1.25e-05\n",
      "Epoch[38/50](200/242) || training loss 0.0009257 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "New best model for val loss : 15.21%! saving the best model..\n",
      "[Val] acc : 92.15%, loss: 0.15, f1: 0.0009908 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[39/50](50/242) || training loss 0.0005315 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[39/50](100/242) || training loss 0.0005797 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[39/50](150/242) || training loss 0.0004232 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Epoch[39/50](200/242) || training loss 0.0006422 || training accuracy 100.00% || training f1_score  1.0 || lr 1.25e-05\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.57%, loss: 0.18, f1: 0.0009743 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[40/50](50/242) || training loss 0.0006183 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[40/50](100/242) || training loss 0.0006594 || training accuracy 99.97% || training f1_score 0.9997 || lr 6.25e-06\n",
      "Epoch[40/50](150/242) || training loss 0.000399 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[40/50](200/242) || training loss 0.0005387 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.10%, loss: 0.16, f1: 0.0009885 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[41/50](50/242) || training loss 0.0004278 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[41/50](100/242) || training loss 0.0003688 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[41/50](150/242) || training loss 0.0003786 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[41/50](200/242) || training loss 0.000432 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.07%, loss: 0.17, f1: 0.00098 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[42/50](50/242) || training loss 0.0004112 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[42/50](100/242) || training loss 0.0003616 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[42/50](150/242) || training loss 0.0002678 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[42/50](200/242) || training loss 0.0004131 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.30%, loss: 0.17, f1: 0.0009827 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[43/50](50/242) || training loss 0.0004087 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[43/50](100/242) || training loss 0.0002995 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[43/50](150/242) || training loss 0.0004149 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[43/50](200/242) || training loss 0.000454 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.27%, loss: 0.16, f1: 0.0009816 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[44/50](50/242) || training loss 0.0005063 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[44/50](100/242) || training loss 0.0005211 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[44/50](150/242) || training loss 0.0004308 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[44/50](200/242) || training loss 0.0005056 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.04%, loss: 0.17, f1: 0.00096 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[45/50](50/242) || training loss 0.0004732 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[45/50](100/242) || training loss 0.0004803 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[45/50](150/242) || training loss 0.0004269 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[45/50](200/242) || training loss 0.000409 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.89%, loss: 0.17, f1: 0.0009505 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[46/50](50/242) || training loss 0.0004104 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[46/50](100/242) || training loss 0.0003527 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[46/50](150/242) || training loss 0.0004676 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[46/50](200/242) || training loss 0.0004363 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.21%, loss: 0.16, f1: 0.0009724 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[47/50](50/242) || training loss 0.0005233 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[47/50](100/242) || training loss 0.000434 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[47/50](150/242) || training loss 0.0004875 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[47/50](200/242) || training loss 0.0007199 || training accuracy 99.97% || training f1_score 0.9998 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.45%, loss: 0.16, f1: 0.0009993 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[48/50](50/242) || training loss 0.0005742 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[48/50](100/242) || training loss 0.0004451 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[48/50](150/242) || training loss 0.002181 || training accuracy 99.88% || training f1_score 0.9956 || lr 6.25e-06\n",
      "Epoch[48/50](200/242) || training loss 0.0008936 || training accuracy 99.97% || training f1_score 0.9994 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.86%, loss: 0.18, f1: 0.0009691 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n",
      "Epoch[49/50](50/242) || training loss 0.0003904 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[49/50](100/242) || training loss 0.0003748 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[49/50](150/242) || training loss 0.0004007 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Epoch[49/50](200/242) || training loss 0.0003705 || training accuracy 100.00% || training f1_score  1.0 || lr 6.25e-06\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.07%, loss: 0.17, f1: 0.0009518 || best acc : 92.15%, best loss: 0.15, best f1: 0.0009908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(config.epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "#     f1_sum = 0\n",
    "    label_list=[]\n",
    "    pred_list=[]\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        label_list+=labels.detach().cpu()\n",
    "        pred_list+=preds.detach().cpu()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "#         f1_sum += f1_score(labels.cpu(), preds.cpu(), average='macro')\n",
    "        if (idx + 1) % config.log_interval == 0:\n",
    "            train_loss = loss_value / config.log_interval\n",
    "            train_acc = matches / config.batch_size / config.log_interval\n",
    "#             train_f1 = f1_sum / config.log_interval\n",
    "            train_f1 = f1_score(label_list, pred_list, average='macro')\n",
    "            current_lr = get_lr(optimizer)\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{config.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || training f1_score {train_f1:4.4} || lr {current_lr}\"\n",
    "            )\n",
    "            logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/f1_score\", train_f1, epoch * len(train_loader) + idx)\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "#             f1_sum = 0\n",
    "            label_list=[]\n",
    "            pred_list=[]\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "#         val_f1_items = []\n",
    "        label_list=[]\n",
    "        pred_list=[]\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            label_list+=labels.detach().cpu()\n",
    "            pred_list+=preds.detach().cpu()\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "#             f1_item = f1_score(labels.cpu(), preds.cpu(), average='macro').item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "#             val_f1_items.append(f1_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_dataset)\n",
    "        val_f1= f1_score(label_list,pred_list,average=\"macro\")\n",
    "#         val_f1 = np.sum(val_f1_items) / len(val_dataset)\n",
    "        \n",
    "#         best_val_loss = min(best_val_loss, val_loss)\n",
    "#         if val_acc > best_val_acc:\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"New best model for val loss : {val_loss:4.2%}! saving the best model..\")\n",
    "            torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "        torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2}, f1: {val_f1:4.4} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}, best f1: {best_val_f1:4.4}\"\n",
    "        )\n",
    "        logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "        logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "        logger.add_scalar(\"Val/f1\", val_f1, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
