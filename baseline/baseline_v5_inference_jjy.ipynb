{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb39e6bd-4283-43ef-ac2e-e90356ab176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b027d-5c6c-4867-9925-5a79b9f3848f",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c09c2d28-110d-4dfa-92f8-3bbd496341da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class Config():\n",
    "    seed = 42\n",
    "    \n",
    "    # 경로\n",
    "#     data_dir = './face_input/train' #\n",
    "    data_dir = './input/data/eval'\n",
    "    # 모델 경로\n",
    "    save_model_dir = './kfoldEnsemble_exp6'\n",
    "    # Output 경로\n",
    "    output_dir = './kfoldEnsemble_output6'\n",
    "    resize = [224, 224]\n",
    "    \n",
    "    # 추론 설정\n",
    "    batch_size = 1000\n",
    "    n_splits = 5 # k - fold\n",
    "\n",
    "config = Config()\n",
    "\n",
    " # -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dabbd-6f32-455c-94c8-13f4c2c9c155",
   "metadata": {},
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924d6db1-09f8-40ea-8d26-76067e10fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, resize, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = Compose([\n",
    "            CenterCrop(height=480, width=320),\n",
    "            Resize(resize[0], resize[1], p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # image = Image.open(self.img_paths[index])\n",
    "        image_path = self.img_paths[index]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453ed437-8415-4b2b-b7a7-65662c10a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = os.path.join(config.data_dir, 'images')\n",
    "info_path = os.path.join(config.data_dir, 'info.csv')\n",
    "info = pd.read_csv(info_path)\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "\n",
    "dataset = TestDataset(img_paths, config.resize)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efdfa81-e780-4bbd-a2da-ca0c1f961062",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431a616e-86c9-4da0-9099-3fdf4f51be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class ResnextMultiheadModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnext50_32x4d(pretrained=True)\n",
    "        self.base_model.fc = Identity()\n",
    "\n",
    "        self.fc_mask_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "        )\n",
    "        self.fc_age_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=3, bias=True)\n",
    "        )\n",
    "        self.fc_gender_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1000, bias=True),\n",
    "            nn.ELU(True),\n",
    "            nn.Dropout(0.5, inplace=True),\n",
    "            nn.Linear(in_features=1000, out_features=2, bias=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        mask = self.fc_mask_classifier(x)\n",
    "        age = self.fc_age_classifier(x)\n",
    "        gender = self.fc_gender_classifier(x)\n",
    "        return mask, age, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ccd61ad-2b93-4a00-ae9a-76f283bcbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(save_model_dir, num, device):\n",
    "    model = ResnextMultiheadModel()\n",
    "\n",
    "    model_path = os.path.join(save_model_dir, f'best_{num}.pth')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27eed1a-c791-4e56-ac5b-47272d66c381",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ea19ca-8f4f-4f00-902d-e26dfb4d70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inference results..[0/5]\n",
      "Calculating inference results..[1/5]\n",
      "Calculating inference results..[2/5]\n",
      "Calculating inference results..[3/5]\n",
      "Calculating inference results..[4/5]\n",
      "Inference Done! Inference result saved at ./kfoldEnsemble_output6/output.csv\n"
     ]
    }
   ],
   "source": [
    "oof_pred = None\n",
    "for i in range(config.n_splits):\n",
    "    print(f\"Calculating inference results..[{i}/{config.n_splits}]\")\n",
    "    model = load_model(config.save_model_dir, i, device).to(device)\n",
    "    model.eval()\n",
    "    mask_predictions = []\n",
    "    age_predictions = []\n",
    "    gender_predictions = []\n",
    "    with torch.no_grad():    \n",
    "        for images in loader:\n",
    "            images = images.to(device)\n",
    "            mask_outs, age_outs, gender_outs = model(images)\n",
    "            mask_predictions.extend(mask_outs.cpu().numpy())\n",
    "            age_predictions.extend(age_outs.cpu().numpy())\n",
    "            gender_predictions.extend(gender_outs.cpu().numpy())\n",
    "    fold_mask_pred = np.array(mask_predictions)\n",
    "    fold_age_pred = np.array(age_predictions)\n",
    "    fold_gender_pred = np.array(gender_predictions)\n",
    "    \n",
    "    if oof_pred is None:\n",
    "        oof_mask_pred = fold_mask_pred / config.n_splits\n",
    "        oof_age_pred = fold_age_pred / config.n_splits\n",
    "        oof_gender_pred = fold_gender_pred / config.n_splits\n",
    "    else:\n",
    "        oof_mask_pred += fold_mask_pred / config.n_splits\n",
    "        oof_age_pred += fold_age_pred / config.n_splits\n",
    "        oof_gender_pred += fold_gender_pred / config.n_splits\n",
    "\n",
    "mask_preds = np.argmax(oof_mask_pred, axis=1)\n",
    "age_preds = np.argmax(oof_age_pred, axis=1)\n",
    "gender_preds = np.argmax(oof_gender_pred, axis=1)\n",
    "\n",
    "preds = mask_preds * 6 + gender_preds * 3 + age_preds\n",
    "\n",
    "info['ans'] = preds\n",
    "os.makedirs(config.output_dir)\n",
    "save_path = os.path.join(config.output_dir, f'output.csv')\n",
    "info.to_csv(save_path, index=False)\n",
    "print(f\"Inference Done! Inference result saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217edc9-4622-4d2c-83b0-fd9ac7406bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6436f-d97c-475f-8674-624ddc63c0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e15efc-b207-4f1f-9da6-2814bcf39b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
