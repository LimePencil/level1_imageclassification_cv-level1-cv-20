{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameter():\n",
    "    EPOCH = 100\n",
    "    BATCH_SIZE = 32\n",
    "    RESIZE = (128, 96)\n",
    "    SAVE_INTERVAL = 10\n",
    "    IMAGE_DIR = '/opt/ml/input/data/train/images'\n",
    "    CSV_DIR = '/opt/ml/input/data/train/train.csv'\n",
    "    SEED = 42\n",
    "    LEARNING_RATE = 0.001\n",
    "    VALIDATION_RATIO = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels():\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(self, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value in [\"mask1\", \"mask2\", \"mask3\", \"mask4\", \"mask5\"]:\n",
    "            return self.MASK\n",
    "        elif value == \"incorrect_mask\":\n",
    "            return self.INCORRECT\n",
    "        else:\n",
    "            return self.NORMAL\n",
    "\n",
    "\n",
    "class GenderLabels():\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(self, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return self.MALE\n",
    "        elif value == \"female\":\n",
    "            return self.FEMALE\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels():\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(self, value: int) -> int:\n",
    "        if value < 30:\n",
    "            return self.YOUNG\n",
    "        elif value < 60:\n",
    "            return self.MIDDLE\n",
    "        else:\n",
    "            return self.OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "        IMG_EXTENSIONS = [\".jpg\", \".JPG\", \".jpeg\", \".JPEG\",\n",
    "                          \".png\", \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\"]\n",
    "        MASK_TYPES = [\"mask1\", \"mask2\", \"mask3\",\n",
    "                      \"mask4\", \"mask5\", \"incorrect_mask\", \"normal\"]\n",
    "        self.df = pd.read_csv(HyperParameter.CSV_DIR)\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            p = os.path.join(HyperParameter.IMAGE_DIR, row.path)\n",
    "            files = os.listdir(p)\n",
    "            for mask_type in MASK_TYPES:\n",
    "                for ext in IMG_EXTENSIONS:\n",
    "                    if mask_type+ext in files:\n",
    "                        self.image_paths.append(os.path.join(p, mask_type+ext))\n",
    "                        self.mask_labels.append(MaskLabels.from_str(mask_type))\n",
    "                        self.gender_labels.append(\n",
    "                            GenderLabels.from_str(row.gender))\n",
    "                        self.age_labels.append(\n",
    "                            AgeLabels.from_number(row.age.item()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return Image.open(self.image_paths[index]), [self.mask_labels[index], self.gender_labels[index], self.age_labels[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "class SplitByHumanDataset(Dataset):\n",
    "    \"\"\"\n",
    "        사람을 기준으로 dataset을 나눴음. Test score과 Validation Score간의 격차를 줄일 수 있다\n",
    "    \n",
    "    \"\"\"\n",
    "    def _get_images(self):\n",
    "        IMG_EXTENSIONS = [\".jpg\", \".JPG\", \".jpeg\", \".JPEG\",\n",
    "                          \".png\", \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\"]\n",
    "        MASK_TYPES = [\"mask1\", \"mask2\", \"mask3\",\n",
    "                      \"mask4\", \"mask5\", \"incorrect_mask\", \"normal\"]\n",
    "        self.df = pd.read_csv(HyperParameter.CSV_DIR)\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            p = os.path.join(HyperParameter.IMAGE_DIR, row.path)\n",
    "            files = os.listdir(p)\n",
    "            for mask_type in MASK_TYPES:\n",
    "                for ext in IMG_EXTENSIONS:\n",
    "                    if mask_type+ext in files:\n",
    "                        self.image_paths.append(os.path.join(p, mask_type+ext))\n",
    "                        self.mask_labels.append(MaskLabels.from_str(mask_type))\n",
    "                        self.gender_labels.append(\n",
    "                            GenderLabels.from_str(row.gender))\n",
    "                        self.age_labels.append(\n",
    "                            AgeLabels.from_number(row.age.item()))\n",
    "\n",
    "    def _split_dataset_by_human(self):\n",
    "        l = len(self.df)\n",
    "        val_size = int(l*HyperParameter.VALIDATION_RATIO)\n",
    "        self.val_index = []\n",
    "        for c in random.choices(range(l), k=val_size):\n",
    "            for i in range(7):\n",
    "                self.val_index.append(c*7+i)\n",
    "        self.train_index = list(set(range(len(self.image_paths)))-set(self.val_index))\n",
    "        self.train_index.sort()\n",
    "        self.val_index.sort()\n",
    "\n",
    "    def __init__(self, train=True,transform=None) -> None:\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self._get_images()\n",
    "        self._split_dataset_by_human()\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            index=self.train_index[index]\n",
    "        else:\n",
    "            index=self.val_index[index]\n",
    "        img =Image.open(self.image_paths[index]), [self.mask_labels[index], self.gender_labels[index], self.age_labels[index]]\n",
    "\n",
    "        if self.transform:\n",
    "            img=self.transform(img)\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_index)\n",
    "        else:\n",
    "            return len(self.val_index)\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_to_single(mask_label:int,gender_label:int,age_label:int) -> int:\n",
    "        \"\"\"\n",
    "            mask, gender, age로 이루어진 label들을 하나의 정수로 변환\n",
    "        \"\"\"\n",
    "        return mask_label*6+gender_label*2+age_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def single_to_multi(label:int):\n",
    "        \"\"\"\n",
    "            mask, gender, age로 이루어진 label들을 하나의 정수로 변환\n",
    "        \"\"\"\n",
    "        mask= label//6\n",
    "        gender=(label//3)%2\n",
    "        age=label%3\n",
    "        return mask,gender,age\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_config(seed):\n",
    "    # https://hoya012.github.io/blog/reproducible_pytorch/\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "seed_config(HyperParameter.SEED)\n",
    "\n",
    "\n",
    "SplitByHumanDataset.multi_to_single()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
