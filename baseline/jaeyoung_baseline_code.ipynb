{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import parser\n",
    "import random\n",
    "import re\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameter():\n",
    "    EPOCH = 10\n",
    "    BATCH_SIZE = 64\n",
    "    RESIZE = (96,128)\n",
    "    SAVE_INTERVAL = 10\n",
    "    LOG_INTERVAL =20\n",
    "    TRAIN_IMAGE_DIR = '/opt/ml/input/data/train/images'\n",
    "    TRAIN_CSV_DIR = '/opt/ml/input/data/train/train.csv'\n",
    "    TEST_IMAGE_DIR = '/opt/ml/input/data/eval/images'\n",
    "    TEST_CSV_DIR = '/opt/ml/input/data/eval/info.csv'\n",
    "    SAVE_DIR = '/opt/ml/model/run1'\n",
    "    SEED = 43\n",
    "    LEARNING_RATE = 0.001\n",
    "    VALIDATION_RATIO = 0.2\n",
    "    NUM_CLASS=18\n",
    "    NUM_MASK_CLASS=3\n",
    "    NUM_GENDER_CLASS=2\n",
    "    NUM_AGE_CLASS=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels():\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(self, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value in [\"mask1\", \"mask2\", \"mask3\", \"mask4\", \"mask5\"]:\n",
    "            return self.MASK\n",
    "        elif value == \"incorrect_mask\":\n",
    "            return self.INCORRECT\n",
    "        else:\n",
    "            return self.NORMAL\n",
    "\n",
    "\n",
    "class GenderLabels():\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(self, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return self.MALE\n",
    "        elif value == \"female\":\n",
    "            return self.FEMALE\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels():\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(self, value: int) -> int:\n",
    "        if value < 30:\n",
    "            return self.YOUNG\n",
    "        elif value < 60:\n",
    "            return self.MIDDLE\n",
    "        else:\n",
    "            return self.OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitByHumanDataset(Dataset):\n",
    "    \"\"\"\n",
    "        사람을 기준으로 dataset을 나눴음. Test score과 Validation Score간의 격차를 줄일 수 있다\n",
    "    \n",
    "    \"\"\"\n",
    "    def _get_images(self):\n",
    "        IMG_EXTENSIONS = [\".jpg\", \".JPG\", \".jpeg\", \".JPEG\",\n",
    "                          \".png\", \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\"]\n",
    "        MASK_TYPES = [\"mask1\", \"mask2\", \"mask3\",\n",
    "                      \"mask4\", \"mask5\", \"incorrect_mask\", \"normal\"]\n",
    "        df = pd.read_csv(HyperParameter.TRAIN_CSV_DIR)\n",
    "        for i in self.df_index:\n",
    "            row = df.iloc[i]\n",
    "            p = os.path.join(HyperParameter.TRAIN_IMAGE_DIR, row.path)\n",
    "            files = os.listdir(p)\n",
    "            for mask_type in MASK_TYPES:\n",
    "                for ext in IMG_EXTENSIONS:\n",
    "                    if mask_type+ext in files:\n",
    "                        self.image_paths.append(os.path.join(p, mask_type+ext))\n",
    "                        self.mask_labels.append(MaskLabels.from_str(mask_type))\n",
    "                        self.gender_labels.append(\n",
    "                            GenderLabels.from_str(row.gender))\n",
    "                        self.age_labels.append(\n",
    "                            AgeLabels.from_number(row.age.item()))\n",
    "\n",
    "\n",
    "    def __init__(self, df_index: list ,transform=None) -> None:\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "        self.transform = transform\n",
    "        self.df_index=df_index\n",
    "        self._get_images()\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img =Image.open(self.image_paths[index])\n",
    "        label=[self.mask_labels[index], self.gender_labels[index], self.age_labels[index]]\n",
    "        if self.transform:\n",
    "            img=self.transform(img)\n",
    "            \n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_train_val():\n",
    "        df=pd.read_csv(HyperParameter.TRAIN_CSV_DIR)\n",
    "        val=int(len(df)*HyperParameter.VALIDATION_RATIO)\n",
    "        train=len(df)-val\n",
    "        t,v=random_split(list(range(len(df))),[train,val])\n",
    "        return t,v\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_to_single(mask_label:int,gender_label:int,age_label:int) -> int:\n",
    "        \"\"\"\n",
    "            mask, gender, age로 이루어진 label들을 하나의 정수로 변환\n",
    "        \"\"\"\n",
    "        return mask_label*6+gender_label*3+age_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def single_to_multi(label:int):\n",
    "        \"\"\"\n",
    "            mask, gender, age로 이루어진 label들을 하나의 정수로 변환\n",
    "        \"\"\"\n",
    "        mask= label//6\n",
    "        gender=(label//3)%2\n",
    "        age=label%3\n",
    "        return mask,gender,age\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self,df, transform):\n",
    "        self.transform=transform\n",
    "        self.image_paths=[os.path.join(HyperParameter.TEST_IMAGE_DIR, img_id) for img_id in df.ImageID]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_config(seed):\n",
    "    # https://hoya012.github.io/blog/reproducible_pytorch/\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "seed_config(HyperParameter.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torchvision.models.resnet50(pretrained=True)\n",
    "model.fc=nn.Linear(model.fc.in_features,HyperParameter.NUM_CLASS)\n",
    "model.to(device)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(HyperParameter.RESIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_idx,val_idx=SplitByHumanDataset.split_train_val()\n",
    "train_dataset=SplitByHumanDataset(train_idx, transform)\n",
    "val_dataset=SplitByHumanDataset(val_idx, transform)\n",
    "\n",
    "criterion=FocalLoss()\n",
    "optimizer=torch.optim.Adam(params=model.parameters(),lr=HyperParameter.LEARNING_RATE)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=HyperParameter.BATCH_SIZE,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=HyperParameter.BATCH_SIZE,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "logger = SummaryWriter(log_dir=HyperParameter.SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10](20/236) || training F1 Score 0.279 || training loss 1.169 || training accuracy 51.64%\n",
      "Epoch[0/10](40/236) || training F1 Score 0.4348 || training loss 0.5959 || training accuracy 66.95%\n",
      "Epoch[0/10](60/236) || training F1 Score 0.5341 || training loss 0.457 || training accuracy 72.66%\n",
      "Epoch[0/10](80/236) || training F1 Score 0.6135 || training loss 0.3489 || training accuracy 77.97%\n",
      "Epoch[0/10](100/236) || training F1 Score 0.5662 || training loss 0.3616 || training accuracy 76.88%\n",
      "Epoch[0/10](120/236) || training F1 Score 0.5933 || training loss 0.3393 || training accuracy 78.20%\n",
      "Epoch[0/10](140/236) || training F1 Score 0.622 || training loss 0.268 || training accuracy 81.09%\n",
      "Epoch[0/10](160/236) || training F1 Score 0.6356 || training loss 0.225 || training accuracy 83.83%\n",
      "Epoch[0/10](180/236) || training F1 Score 0.677 || training loss 0.229 || training accuracy 83.44%\n",
      "Epoch[0/10](200/236) || training F1 Score 0.6462 || training loss 0.2588 || training accuracy 82.73%\n",
      "Epoch[0/10](220/236) || training F1 Score 0.6387 || training loss 0.2582 || training accuracy 82.81%\n",
      "New best model for f1 score : 44.48%! saving the best model..\n",
      "[Val] f1 : 44.48%, acc : 61.57%, loss:  0.8 || best f1 : 44.48%, best acc : 61.57%, best loss:  0.8\n",
      "------------------------------------------------------------\n",
      "Epoch[1/10](20/236) || training F1 Score 0.7248 || training loss 0.1462 || training accuracy 86.95%\n",
      "Epoch[1/10](40/236) || training F1 Score 0.7757 || training loss 0.1283 || training accuracy 88.83%\n",
      "Epoch[1/10](60/236) || training F1 Score 0.7338 || training loss 0.1871 || training accuracy 86.56%\n",
      "Epoch[1/10](80/236) || training F1 Score 0.6757 || training loss 0.1891 || training accuracy 84.69%\n",
      "Epoch[1/10](100/236) || training F1 Score 0.7238 || training loss 0.1607 || training accuracy 86.88%\n",
      "Epoch[1/10](120/236) || training F1 Score 0.7536 || training loss 0.1371 || training accuracy 87.81%\n",
      "Epoch[1/10](140/236) || training F1 Score 0.7976 || training loss 0.1391 || training accuracy 87.50%\n",
      "Epoch[1/10](160/236) || training F1 Score 0.7307 || training loss 0.1447 || training accuracy 87.03%\n",
      "Epoch[1/10](180/236) || training F1 Score 0.7513 || training loss 0.1692 || training accuracy 87.58%\n",
      "Epoch[1/10](200/236) || training F1 Score 0.7284 || training loss 0.185 || training accuracy 85.86%\n",
      "Epoch[1/10](220/236) || training F1 Score 0.7753 || training loss 0.164 || training accuracy 87.73%\n",
      "New best model for f1 score : 64.08%! saving the best model..\n",
      "[Val] f1 : 64.08%, acc : 79.40%, loss: 0.31 || best f1 : 64.08%, best acc : 79.40%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[2/10](20/236) || training F1 Score 0.8158 || training loss 0.1218 || training accuracy 89.77%\n",
      "Epoch[2/10](40/236) || training F1 Score 0.7388 || training loss 0.1245 || training accuracy 88.44%\n",
      "Epoch[2/10](60/236) || training F1 Score 0.8418 || training loss 0.09408 || training accuracy 91.17%\n",
      "Epoch[2/10](80/236) || training F1 Score 0.8703 || training loss 0.08932 || training accuracy 91.41%\n",
      "Epoch[2/10](100/236) || training F1 Score 0.8644 || training loss 0.08091 || training accuracy 92.89%\n",
      "Epoch[2/10](120/236) || training F1 Score 0.8092 || training loss 0.1044 || training accuracy 90.86%\n",
      "Epoch[2/10](140/236) || training F1 Score 0.7743 || training loss 0.09029 || training accuracy 90.08%\n",
      "Epoch[2/10](160/236) || training F1 Score 0.8165 || training loss 0.07776 || training accuracy 92.42%\n",
      "Epoch[2/10](180/236) || training F1 Score 0.8864 || training loss 0.06263 || training accuracy 94.06%\n",
      "Epoch[2/10](200/236) || training F1 Score 0.8662 || training loss 0.07161 || training accuracy 92.66%\n",
      "Epoch[2/10](220/236) || training F1 Score 0.8459 || training loss 0.07294 || training accuracy 93.36%\n",
      "New best model for f1 score : 68.59%! saving the best model..\n",
      "[Val] f1 : 68.59%, acc : 80.85%, loss: 0.35 || best f1 : 68.59%, best acc : 80.85%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[3/10](20/236) || training F1 Score 0.873 || training loss 0.06899 || training accuracy 93.44%\n",
      "Epoch[3/10](40/236) || training F1 Score 0.8842 || training loss 0.06273 || training accuracy 94.77%\n",
      "Epoch[3/10](60/236) || training F1 Score 0.8583 || training loss 0.0991 || training accuracy 91.95%\n",
      "Epoch[3/10](80/236) || training F1 Score 0.8776 || training loss 0.07738 || training accuracy 92.50%\n",
      "Epoch[3/10](100/236) || training F1 Score 0.8419 || training loss 0.05533 || training accuracy 94.77%\n",
      "Epoch[3/10](120/236) || training F1 Score 0.8739 || training loss 0.0798 || training accuracy 93.67%\n",
      "Epoch[3/10](140/236) || training F1 Score 0.8861 || training loss 0.05123 || training accuracy 95.23%\n",
      "Epoch[3/10](160/236) || training F1 Score 0.9133 || training loss 0.05091 || training accuracy 95.08%\n",
      "Epoch[3/10](180/236) || training F1 Score 0.9032 || training loss 0.07293 || training accuracy 94.06%\n",
      "Epoch[3/10](200/236) || training F1 Score 0.8627 || training loss 0.06764 || training accuracy 92.34%\n",
      "Epoch[3/10](220/236) || training F1 Score 0.8421 || training loss 0.08508 || training accuracy 91.72%\n",
      "[Val] f1 : 67.70%, acc : 79.77%, loss: 0.34 || best f1 : 68.59%, best acc : 80.85%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[4/10](20/236) || training F1 Score 0.9052 || training loss 0.04568 || training accuracy 96.33%\n",
      "Epoch[4/10](40/236) || training F1 Score 0.9185 || training loss 0.04783 || training accuracy 94.92%\n",
      "Epoch[4/10](60/236) || training F1 Score 0.9001 || training loss 0.04222 || training accuracy 95.70%\n",
      "Epoch[4/10](80/236) || training F1 Score 0.9351 || training loss 0.04217 || training accuracy 96.09%\n",
      "Epoch[4/10](100/236) || training F1 Score 0.942 || training loss 0.0364 || training accuracy 96.33%\n",
      "Epoch[4/10](120/236) || training F1 Score 0.9107 || training loss 0.04277 || training accuracy 95.62%\n",
      "Epoch[4/10](140/236) || training F1 Score 0.9113 || training loss 0.04141 || training accuracy 95.31%\n",
      "Epoch[4/10](160/236) || training F1 Score 0.9206 || training loss 0.05717 || training accuracy 94.77%\n",
      "Epoch[4/10](180/236) || training F1 Score 0.9082 || training loss 0.06572 || training accuracy 93.98%\n",
      "Epoch[4/10](200/236) || training F1 Score 0.8625 || training loss 0.06589 || training accuracy 93.98%\n",
      "Epoch[4/10](220/236) || training F1 Score 0.9173 || training loss 0.0493 || training accuracy 96.09%\n",
      "[Val] f1 : 64.71%, acc : 79.50%, loss: 0.42 || best f1 : 68.59%, best acc : 80.85%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[5/10](20/236) || training F1 Score 0.9296 || training loss 0.04321 || training accuracy 96.17%\n",
      "Epoch[5/10](40/236) || training F1 Score 0.9113 || training loss 0.0366 || training accuracy 95.62%\n",
      "Epoch[5/10](60/236) || training F1 Score 0.8948 || training loss 0.0453 || training accuracy 96.09%\n",
      "Epoch[5/10](80/236) || training F1 Score 0.898 || training loss 0.04259 || training accuracy 96.02%\n",
      "Epoch[5/10](100/236) || training F1 Score 0.9113 || training loss 0.04799 || training accuracy 95.00%\n",
      "Epoch[5/10](120/236) || training F1 Score 0.9193 || training loss 0.03253 || training accuracy 97.03%\n",
      "Epoch[5/10](140/236) || training F1 Score 0.9003 || training loss 0.03754 || training accuracy 96.64%\n",
      "Epoch[5/10](160/236) || training F1 Score 0.937 || training loss 0.03694 || training accuracy 96.48%\n",
      "Epoch[5/10](180/236) || training F1 Score 0.9076 || training loss 0.03304 || training accuracy 96.56%\n",
      "Epoch[5/10](200/236) || training F1 Score 0.9212 || training loss 0.0536 || training accuracy 95.16%\n",
      "Epoch[5/10](220/236) || training F1 Score 0.952 || training loss 0.04107 || training accuracy 96.25%\n",
      "[Val] f1 : 68.34%, acc : 82.79%, loss:  0.4 || best f1 : 68.59%, best acc : 82.79%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[6/10](20/236) || training F1 Score 0.9347 || training loss 0.02804 || training accuracy 97.27%\n",
      "Epoch[6/10](40/236) || training F1 Score 0.9467 || training loss 0.02794 || training accuracy 97.73%\n",
      "Epoch[6/10](60/236) || training F1 Score 0.9722 || training loss 0.01955 || training accuracy 97.89%\n",
      "Epoch[6/10](80/236) || training F1 Score 0.9486 || training loss 0.02206 || training accuracy 97.66%\n",
      "Epoch[6/10](100/236) || training F1 Score 0.9729 || training loss 0.02885 || training accuracy 97.58%\n",
      "Epoch[6/10](120/236) || training F1 Score 0.9748 || training loss 0.02191 || training accuracy 98.12%\n",
      "Epoch[6/10](140/236) || training F1 Score 0.923 || training loss 0.04112 || training accuracy 96.95%\n",
      "Epoch[6/10](160/236) || training F1 Score 0.9286 || training loss 0.05183 || training accuracy 95.94%\n",
      "Epoch[6/10](180/236) || training F1 Score 0.9339 || training loss 0.0424 || training accuracy 95.94%\n",
      "Epoch[6/10](200/236) || training F1 Score 0.9372 || training loss 0.03983 || training accuracy 96.02%\n",
      "Epoch[6/10](220/236) || training F1 Score 0.9128 || training loss 0.04229 || training accuracy 95.94%\n",
      "[Val] f1 : 62.46%, acc : 78.36%, loss: 0.46 || best f1 : 68.59%, best acc : 82.79%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[7/10](20/236) || training F1 Score 0.9595 || training loss 0.02945 || training accuracy 97.42%\n",
      "Epoch[7/10](40/236) || training F1 Score 0.9601 || training loss 0.02431 || training accuracy 97.73%\n",
      "Epoch[7/10](60/236) || training F1 Score 0.9448 || training loss 0.02122 || training accuracy 97.81%\n",
      "Epoch[7/10](80/236) || training F1 Score 0.9701 || training loss 0.02856 || training accuracy 97.42%\n",
      "Epoch[7/10](100/236) || training F1 Score 0.9544 || training loss 0.03645 || training accuracy 97.50%\n",
      "Epoch[7/10](120/236) || training F1 Score 0.9499 || training loss 0.03333 || training accuracy 97.03%\n",
      "Epoch[7/10](140/236) || training F1 Score 0.9445 || training loss 0.02728 || training accuracy 97.58%\n",
      "Epoch[7/10](160/236) || training F1 Score 0.9159 || training loss 0.04556 || training accuracy 95.62%\n",
      "Epoch[7/10](180/236) || training F1 Score 0.9628 || training loss 0.04392 || training accuracy 97.27%\n",
      "Epoch[7/10](200/236) || training F1 Score 0.9234 || training loss 0.03951 || training accuracy 96.17%\n",
      "Epoch[7/10](220/236) || training F1 Score 0.9262 || training loss 0.03437 || training accuracy 96.56%\n",
      "[Val] f1 : 66.70%, acc : 79.34%, loss: 0.35 || best f1 : 68.59%, best acc : 82.79%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[8/10](20/236) || training F1 Score 0.9595 || training loss 0.03866 || training accuracy 96.80%\n",
      "Epoch[8/10](40/236) || training F1 Score 0.942 || training loss 0.02902 || training accuracy 96.41%\n",
      "Epoch[8/10](60/236) || training F1 Score 0.9804 || training loss 0.02657 || training accuracy 98.05%\n",
      "Epoch[8/10](80/236) || training F1 Score 0.9497 || training loss 0.01932 || training accuracy 97.89%\n",
      "Epoch[8/10](100/236) || training F1 Score 0.9569 || training loss 0.03019 || training accuracy 97.66%\n",
      "Epoch[8/10](120/236) || training F1 Score 0.96 || training loss 0.02644 || training accuracy 97.50%\n",
      "Epoch[8/10](140/236) || training F1 Score 0.9479 || training loss 0.04216 || training accuracy 96.80%\n",
      "Epoch[8/10](160/236) || training F1 Score 0.9009 || training loss 0.05868 || training accuracy 94.77%\n",
      "Epoch[8/10](180/236) || training F1 Score 0.9562 || training loss 0.03906 || training accuracy 97.34%\n",
      "Epoch[8/10](200/236) || training F1 Score 0.9486 || training loss 0.0303 || training accuracy 97.11%\n",
      "Epoch[8/10](220/236) || training F1 Score 0.9536 || training loss 0.02643 || training accuracy 97.03%\n",
      "New best model for f1 score : 70.75%! saving the best model..\n",
      "[Val] f1 : 70.75%, acc : 83.00%, loss: 0.42 || best f1 : 70.75%, best acc : 83.00%, best loss: 0.31\n",
      "------------------------------------------------------------\n",
      "Epoch[9/10](20/236) || training F1 Score 0.9375 || training loss 0.02109 || training accuracy 98.20%\n",
      "Epoch[9/10](40/236) || training F1 Score 0.9665 || training loss 0.019 || training accuracy 98.36%\n",
      "Epoch[9/10](60/236) || training F1 Score 0.9622 || training loss 0.01885 || training accuracy 97.73%\n",
      "Epoch[9/10](80/236) || training F1 Score 0.9693 || training loss 0.0239 || training accuracy 97.81%\n",
      "Epoch[9/10](100/236) || training F1 Score 0.9337 || training loss 0.02755 || training accuracy 97.42%\n",
      "Epoch[9/10](120/236) || training F1 Score 0.9632 || training loss 0.0175 || training accuracy 98.28%\n",
      "Epoch[9/10](140/236) || training F1 Score 0.9615 || training loss 0.02428 || training accuracy 97.66%\n",
      "Epoch[9/10](160/236) || training F1 Score 0.9535 || training loss 0.02 || training accuracy 97.89%\n",
      "Epoch[9/10](180/236) || training F1 Score 0.9779 || training loss 0.01566 || training accuracy 98.44%\n",
      "Epoch[9/10](200/236) || training F1 Score 0.9687 || training loss 0.01576 || training accuracy 97.73%\n",
      "Epoch[9/10](220/236) || training F1 Score 0.9414 || training loss 0.02175 || training accuracy 97.81%\n",
      "[Val] f1 : 67.17%, acc : 81.44%, loss: 0.42 || best f1 : 70.75%, best acc : 83.00%, best loss: 0.31\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1=0\n",
    "for epoch in range(HyperParameter.EPOCH):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    label_list=[]\n",
    "    pred_list=[]\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = SplitByHumanDataset.multi_to_single(*labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        label_list+=labels.detach().cpu()\n",
    "        pred_list+=preds.detach().cpu()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % HyperParameter.LOG_INTERVAL == 0:\n",
    "            train_loss = loss_value / HyperParameter.LOG_INTERVAL\n",
    "            train_acc = matches / HyperParameter.BATCH_SIZE / HyperParameter.LOG_INTERVAL\n",
    "            train_f1=f1_score(label_list,pred_list,average=\"macro\")\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{HyperParameter.EPOCH}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training F1 Score {train_f1:4.4} || training loss {train_loss:4.4} || training accuracy {train_acc:4.2%}\"\n",
    "            )\n",
    "            logger.add_scalar(\"Train/Loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/Accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "            logger.add_scalar(\"Train/F1_Score\", train_acc, epoch * len(train_loader) + idx)\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "            label_list=[]\n",
    "            pred_list=[]\n",
    "    # evaluation session\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss=0\n",
    "        val_acc=0\n",
    "        label_list=[]\n",
    "        pred_list=[]\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = SplitByHumanDataset.multi_to_single(*labels).to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            label_list+=labels.detach().cpu()\n",
    "            pred_list+=preds.detach().cpu()\n",
    "            val_acc+=(labels==preds).sum().item()\n",
    "            val_loss+= criterion(outs, labels).item()\n",
    "\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_acc / len(label_list)\n",
    "        val_f1= f1_score(label_list,pred_list,average=\"macro\")\n",
    "        best_val_loss = min(best_val_loss, val_loss)\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "        if val_f1 > best_val_f1:\n",
    "            print(f\"New best model for f1 score : {val_f1:4.2%}! saving the best model..\")\n",
    "            torch.save(model.state_dict(), f\"{HyperParameter.SAVE_DIR}/best_model.pth\")\n",
    "            best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), f\"{HyperParameter.SAVE_DIR}/last_model.pth\")\n",
    "        print(f\"[Val] f1 : {val_f1:4.2%}, acc : {val_acc:4.2%}, loss: {val_loss:4.2} || best f1 : {best_val_f1:4.2%}, best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\")\n",
    "        logger.add_scalar(\"Val/Loss\", val_loss, epoch)\n",
    "        logger.add_scalar(\"Val/Accuracy\", val_acc, epoch)\n",
    "        logger.add_scalar(\"Val/F1_Score\",val_f1,epoch)\n",
    "        print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done! Inference result saved at /opt/ml/model/run1/output.csv\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(HyperParameter.SAVE_DIR,\"best_model.pth\"),map_location=device))\n",
    "model.eval()\n",
    "test_df=pd.read_csv(HyperParameter.TEST_CSV_DIR)\n",
    "test_dataset=TestDataset(df=test_df,transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=HyperParameter.BATCH_SIZE,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for idx, images in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "test_df['ans'] = preds\n",
    "save_path = os.path.join(HyperParameter.SAVE_DIR,'output.csv')\n",
    "test_df.to_csv(save_path, index=False)\n",
    "print(f\"Inference Done! Inference result saved at {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c239fde4eb24d585007cef1e495495261fb6bbf5570e219d9bc38ff69d41be2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
